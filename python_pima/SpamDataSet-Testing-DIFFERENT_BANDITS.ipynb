{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the testing data (Unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import numpy\n",
    "from sklearn import metrics\n",
    "plt.rcParams['figure.figsize'] = (15, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples 491\n",
      "Number of validation examples 123\n",
      "Number of testing examples 154\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = np.load('./pima/X_train.npy')\n",
    "y_train = np.load('./pima/y_train.npy')\n",
    "X_test = np.load('./pima/X_test.npy')\n",
    "y_test = np.load('./pima/y_test.npy')\n",
    "X_deploy = np.load('./pima/X_deploy.npy')\n",
    "y_deploy = np.load('./pima/y_deploy.npy')\n",
    "\n",
    "print('Number of training examples',len(X_train))\n",
    "print('Number of validation examples',len(X_test))\n",
    "print('Number of testing examples',len(X_deploy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the classifiers as the training time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "clf_neigh.fit(X_train, y_train)\n",
    "from sklearn.svm import LinearSVC\n",
    "clf_svm_linear = LinearSVC(C=20.0)\n",
    "clf_svm_linear.fit(X_train, y_train)\n",
    "from sklearn.svm import SVC\n",
    "clf_svm = SVC(C=5.0, kernel='rbf')\n",
    "clf_svm.fit(X_train, y_train)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dt = DecisionTreeClassifier(min_samples_split=2)\n",
    "clf_dt.fit(X_train, y_train)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dt_IG = DecisionTreeClassifier(criterion='entropy', min_samples_split=2)\n",
    "clf_dt_IG.fit(X_train, y_train)\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_dt_BGKN = BaggingClassifier(KNeighborsClassifier(n_neighbors=5),\n",
    "                             max_samples=0.5, max_features=0.5)\n",
    "clf_dt_BGKN.fit(X_train, y_train)\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dt_BGDT = BaggingClassifier(DecisionTreeClassifier(criterion='entropy', min_samples_split=2),\n",
    "                             max_samples=0.5, max_features=0.5)\n",
    "clf_dt_BGDT.fit(X_train, y_train)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_dt_RF = RandomForestClassifier()\n",
    "#Training\n",
    "start_time = time.time()\n",
    "clf_dt_RF.fit(X_train, y_train)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf_dt_AD = AdaBoostClassifier()\n",
    "clf_dt_AD.fit(X_train, y_train)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_NB = GaussianNB()\n",
    "clf_NB.fit(X_train, y_train)\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf_dt_LDA = LinearDiscriminantAnalysis()\n",
    "clf_dt_LDA.fit(X_train, y_train)\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "clf_dt_QDA = QuadraticDiscriminantAnalysis()\n",
    "clf_dt_QDA.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg = LogisticRegression(C=1e5)\n",
    "LogReg.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "GP = GaussianProcessClassifier()\n",
    "GP.fit(X_train, y_train)\n",
    "\n",
    "import lightgbm as lgb\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "gbm = lgb.LGBMClassifier()\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "import xgboost as xgb\n",
    "XG_Boost = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "labelsTrain = np_utils.to_categorical(y_train)\n",
    "labelsTest = np_utils.to_categorical(y_test)                                              \n",
    "model = Sequential()\n",
    "model.add(Dense(35,\n",
    "                input_shape=(8,), \n",
    "                activation=\"relu\"))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.load_weights('PimaModelbest.hdf5')\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer='Adadelta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (Unable to open file: name = './ucb1/spam5.hdf5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9cd6a3b1fa05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./UCB1/spam5.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adadelta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Adadelta, adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         '''\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/private/var/folders/my/m6ynh3bn6tq06h7xr3js0z7r0000gn/T/pip-z0d9zbgm-build/h5py/_objects.c:2853)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/private/var/folders/my/m6ynh3bn6tq06h7xr3js0z7r0000gn/T/pip-z0d9zbgm-build/h5py/_objects.c:2811)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (/private/var/folders/my/m6ynh3bn6tq06h7xr3js0z7r0000gn/T/pip-z0d9zbgm-build/h5py/h5f.c:2099)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (Unable to open file: name = './ucb1/spam5.hdf5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# MAB_NN(2.5%REMOVED) MODEL1\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(35, input_dim=8, activation='relu')) # sigmoid, relu, tanh, W_regularizer=l2(0.01)\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Dense(2, init='uniform', activation='sigmoid'))\n",
    "model1.load_weights('./UCB1/pima5.hdf5')\n",
    "model1.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy']) # Adadelta, adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MAB_NN(7.5%REMOVED) MODEL2\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(35, input_dim=8, activation='relu')) # sigmoid, relu, tanh, W_regularizer=l2(0.01)\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Dense(2, init='uniform', activation='sigmoid'))\n",
    "model2.load_weights('./UCB1/pima2.hdf5')\n",
    "model2.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy']) # Adadelta, adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAB_NN(65%REMOVED) MODEL3\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(35, input_dim=8, activation='relu')) # sigmoid, relu, tanh, W_regularizer=l2(0.01)\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Dense(2, init='uniform', activation='sigmoid'))\n",
    "model3.load_weights('./UCB1/pima25.hdf5')\n",
    "model3.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy']) # Adadelta, adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAB_NN(85%REMOVED) MODEL4\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(35, input_dim=8, activation='relu')) # sigmoid, relu, tanh, W_regularizer=l2(0.01)\n",
    "model4.add(Dropout(0.25))\n",
    "model4.add(Dense(2, init='uniform', activation='sigmoid'))\n",
    "model4.load_weights('./UCB1/pima33.hdf5')\n",
    "model4.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy']) # Adadelta, adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Espsilon Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_EG = Sequential()\n",
    "model_EG.add(Dense(35, input_dim=8, activation='relu')) # sigmoid, relu, tanh, W_regularizer=l2(0.01)\n",
    "model_EG.add(Dropout(0.25))\n",
    "model_EG.add(Dense(2, init='uniform', activation='sigmoid'))\n",
    "model_EG.load_weights('./EpsilonGreedy/pima5.hdf5')\n",
    "model_EG.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy']) # Adadelta, adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annealing Epsilon Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_AEG = Sequential()\n",
    "model_AEG.add(Dense(35, input_dim=8, activation='relu')) # sigmoid, relu, tanh, W_regularizer=l2(0.01)\n",
    "model_AEG.add(Dropout(0.25))\n",
    "model_AEG.add(Dense(2, init='uniform', activation='sigmoid'))\n",
    "model_AEG.load_weights('./AnnealingEpsilonGreedy/pima5.hdf5')\n",
    "model_AEG.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy']) # Adadelta, adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOFTMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_SM = Sequential()\n",
    "model_SM.add(Dense(35, input_dim=8, activation='relu')) # sigmoid, relu, tanh, W_regularizer=l2(0.01)\n",
    "model_SM.add(Dropout(0.25))\n",
    "model_SM.add(Dense(2, init='uniform', activation='sigmoid'))\n",
    "model_SM.load_weights('./Softmax/pima5.hdf5')\n",
    "model_SM.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy']) # Adadelta, adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANNEELYING SOFTMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ASM = Sequential()\n",
    "model_ASM.add(Dense(35, input_dim=8, activation='relu')) # sigmoid, relu, tanh, W_regularizer=l2(0.01)\n",
    "model_ASM.add(Dropout(0.25))\n",
    "model_ASM.add(Dense(2, init='uniform', activation='sigmoid'))\n",
    "model_ASM.load_weights('./AnnealingSoftmax/pima5.hdf5')\n",
    "model_ASM.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy']) # Adadelta, adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THOMPSON SAMBLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_TS = Sequential()\n",
    "model_TS.add(Dense(35, input_dim=8, activation='relu')) # sigmoid, relu, tanh, W_regularizer=l2(0.01)\n",
    "model_TS.add(Dropout(0.25))\n",
    "model_TS.add(Dense(2, init='uniform', activation='sigmoid'))\n",
    "model_TS.load_weights('./thompson_sampling/pima5.hdf5')\n",
    "model_TS.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy']) # Adadelta, adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HEDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_HG = Sequential()\n",
    "model_HG.add(Dense(35, input_dim=8, activation='relu')) # sigmoid, relu, tanh, W_regularizer=l2(0.01)\n",
    "model_HG.add(Dropout(0.25))\n",
    "model_HG.add(Dense(2, init='uniform', activation='sigmoid'))\n",
    "model_HG.load_weights('./Hedge/pima5.hdf5')\n",
    "model_HG.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy']) # Adadelta, adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_EXP = Sequential()\n",
    "model_EXP.add(Dense(35, input_dim=8, activation='relu')) # sigmoid, relu, tanh, W_regularizer=l2(0.01)\n",
    "model_EXP.add(Dropout(0.25))\n",
    "model_EXP.add(Dense(2, init='uniform', activation='sigmoid'))\n",
    "model_EXP.load_weights('./Exp3/pima5.hdf5')\n",
    "model_EXP.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy']) # Adadelta, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "y_pred_neigh = clf_neigh.predict(X_deploy)\n",
    "print(\"The time of KNN is                       %s seconds\" % (time.time() - start_time))\n",
    "# Linear SVM \n",
    "start_time = time.time()\n",
    "y_pred_svm_linear = clf_svm_linear.predict(X_deploy)\n",
    "print(\"The time of LSVM is                      %s seconds \" % (time.time() - start_time))\n",
    "# SVM kernel='rbf'\n",
    "start_time = time.time()\n",
    "y_pred_svm = clf_svm.predict(X_deploy)\n",
    "print(\"The time of SVM is                       %s seconds \" % (time.time() - start_time))\n",
    "# DT with gini\n",
    "start_time = time.time()\n",
    "y_pred_gtgini = clf_dt.predict(X_deploy)\n",
    "print(\"The time of DT_gini is                   %s seconds \" % (time.time() - start_time))\n",
    "# DT with entorpy\n",
    "start_time = time.time()\n",
    "y_pred_dt_IG = clf_dt_IG.predict(X_deploy)\n",
    "print(\"The time of DT is                        %s seconds\" % (time.time() - start_time))\n",
    "# Bagging with Knn\n",
    "start_time = time.time()\n",
    "y_pred_dt_BGKN = clf_dt_BGKN.predict(X_deploy)\n",
    "print(\"The time of Bagging Knn is               %s seconds\" % (time.time() - start_time))\n",
    "# Bagging with DT with gini\n",
    "start_time = time.time()\n",
    "y_pred_dt_BGDT = clf_dt_BGDT.predict(X_deploy)\n",
    "print(\"The time of Bagging DT is                 %s seconds \" % (time.time() - start_time))\n",
    "# Random Forest with DT with gini \n",
    "start_time = time.time()\n",
    "y_pred_dt_RF = clf_dt_RF.predict(X_deploy)\n",
    "print(\"The time of Random Forest is              %s seconds \" % (time.time() - start_time))\n",
    "# Ada Boost\n",
    "start_time = time.time()\n",
    "y_pred_dt_AD = clf_dt_AD.predict(X_deploy)\n",
    "print(\"The time of Ada Boost is                  %s seconds \" % (time.time() - start_time))\n",
    "# Naive Bayes\n",
    "start_time = time.time()\n",
    "y_pred_NB = clf_NB.predict(X_deploy)\n",
    "print(\"The time of Naive Bayes is                 %s seconds \" % (time.time() - start_time))\n",
    "# LDA\n",
    "start_time = time.time()\n",
    "y_pred_dt_LDA = clf_dt_LDA.predict(X_deploy)\n",
    "print(\"The time of LDA is                         %s seconds \" % (time.time() - start_time))\n",
    "# QDA\n",
    "start_time = time.time()\n",
    "y_pred_dt_QDA = clf_dt_QDA.predict(X_deploy)\n",
    "print(\"The time of QDA is                         %s seconds \" % (time.time() - start_time))\n",
    "# Logistic Regression\n",
    "start_time = time.time()\n",
    "y_pred_LR = LogReg.predict(X_deploy)\n",
    "print(\"The time of Logistic Regression is         %s seconds \" % (time.time() - start_time))\n",
    "# Gaussian Process Classifier\n",
    "start_time = time.time()\n",
    "y_pred_GP = GP.predict(X_deploy)\n",
    "print(\"The time of Gaussian Process Classifier is  %s seconds \" % (time.time() - start_time))\n",
    "# LightGBM\n",
    "start_time = time.time()\n",
    "y_pred_gbm = gbm.predict(X_deploy)\n",
    "print(\"The time of LightGBM is                     %s seconds \" % (time.time() - start_time))\n",
    "# xgboost\n",
    "start_time = time.time()\n",
    "y_pred_xgboost = XG_Boost.predict(X_deploy)\n",
    "print(\"The time of xgboost is                     %s seconds \" % (time.time() - start_time))\n",
    "# NN\n",
    "start_time = time.time()\n",
    "y_pred_NN = model.predict_classes(X_deploy, verbose=0)\n",
    "print(\"The time of NN is                           %s seconds \" % (time.time() - start_time))\n",
    "# NN 2.5% removed neurals\n",
    "start_time = time.time()\n",
    "y_pred_NN1 = model1.predict_classes(X_deploy, verbose=0)\n",
    "print(\"The time of NN2.5 Removed is               %s seconds \" % (time.time() - start_time))\n",
    "# NN 7.5% removed neurals\n",
    "start_time = time.time()\n",
    "y_pred_NN2 = model2.predict_classes(X_deploy, verbose=0)\n",
    "print(\"The time of NN7.5 Removed is               %s seconds \" % (time.time() - start_time))\n",
    "# NN 65% removed neurals\n",
    "start_time = time.time()\n",
    "y_pred_NN3 = model3.predict_classes(X_deploy, verbose=0)\n",
    "print(\"The time of NN65 Removed is                %s seconds \" % (time.time() - start_time))\n",
    "# NN 85% removed neurals\n",
    "start_time = time.time()\n",
    "y_pred_NN4 = model4.predict_classes(X_deploy, verbose=0)\n",
    "print(\"The time of NN85 Removed is                %s seconds \" % (time.time() - start_time))\n",
    "# NN 20% removed neurals USING EPSILON GREEDY\n",
    "start_time = time.time()\n",
    "y_pred_EG = model_EG.predict_classes(X_deploy, verbose=0)\n",
    "print(\"The time of EPSILON GREEDY Removed is      %s seconds \" % (time.time() - start_time))\n",
    "# NN 20% removed neurals USING ANNEELYING EPSILON GREEDY\n",
    "start_time = time.time()\n",
    "y_pred_AEG = model_AEG.predict_classes(X_deploy, verbose=0)\n",
    "print(\"The time of DECAYING EPSILON GREEDY Removed is  %s seconds \" % (time.time() - start_time))\n",
    "# NN 20% removed neurals USING SOFTMAX\n",
    "start_time = time.time()\n",
    "y_pred_SM = model_SM.predict_classes(X_deploy, verbose=0)\n",
    "print(\"The time of SOFTMAX Removed is                  %s seconds \" % (time.time() - start_time))\n",
    "# NN 20% removed neurals USING DECAYING SOFTMAX\n",
    "start_time = time.time()\n",
    "y_pred_ASM = model_ASM.predict_classes(X_deploy, verbose=0)\n",
    "print(\"The time of DECAYING SOFTMAX Removed is         %s seconds \" % (time.time() - start_time))\n",
    "# NN 20% removed neurals USING THOMPSON SAMPLING\n",
    "start_time = time.time()\n",
    "y_pred_TS = model_TS.predict_classes(X_deploy, verbose=0)\n",
    "print(\"The time of THOMPSON SAMPLING Removed is        %s seconds \" % (time.time() - start_time))\n",
    "# NN 20% removed neurals USING HEDGE\n",
    "start_time = time.time()\n",
    "y_pred_HG = model_HG.predict_classes(X_deploy, verbose=0)\n",
    "print(\"The time of HEDGE Removed is                    %s seconds \" % (time.time() - start_time))\n",
    "# NN 20% removed neurals USING EXP3\n",
    "start_time = time.time()\n",
    "y_pred_EXP = model_EXP.predict_classes(X_deploy, verbose=0)\n",
    "print(\"The time of EXP3 Removed is                    %s seconds \" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Accuracy of the models on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The accuracy of KNN:          \\t\", metrics.accuracy_score(y_deploy, y_pred_neigh))\n",
    "print(\"The accuracy of LSVM:         \\t\", metrics.accuracy_score(y_deploy, y_pred_svm_linear))\n",
    "print(\"The accuracy of SVM:          \\t\", metrics.accuracy_score(y_deploy, y_pred_svm))\n",
    "print(\"The accuracy of DT_gini:      \\t\", metrics.accuracy_score(y_deploy, y_pred_gtgini))\n",
    "print(\"The accuracy of DT_entorpy:   \\t\", metrics.accuracy_score(y_deploy, y_pred_dt_IG))\n",
    "print(\"The accuracy of Bagging Knn:  \\t\", metrics.accuracy_score(y_deploy, y_pred_dt_BGKN))\n",
    "print(\"The accuracy of Bagging DT:   \\t\", metrics.accuracy_score(y_deploy, y_pred_dt_BGDT))\n",
    "print(\"The accuracy of Random Forest:\\t\", metrics.accuracy_score(y_deploy, y_pred_dt_RF))\n",
    "print(\"The accuracy of Ada Boost:    \\t\", metrics.accuracy_score(y_deploy, y_pred_dt_AD))\n",
    "print(\"The accuracy of Naive Bayes:  \\t\", metrics.accuracy_score(y_deploy, y_pred_NB))\n",
    "print(\"The accuracy of LDA:          \\t\", metrics.accuracy_score(y_deploy, y_pred_dt_LDA))\n",
    "print(\"The accuracy of QDA:          \\t\", metrics.accuracy_score(y_deploy, y_pred_dt_QDA))\n",
    "print(\"The accuracy of Log. Reg.:    \\t\", metrics.accuracy_score(y_deploy, y_pred_LR))\n",
    "print(\"The accuracy of GP CLASSI. :  \\t\", metrics.accuracy_score(y_deploy, y_pred_GP))\n",
    "print(\"The accuracy of LightGBM:     \\t\", metrics.accuracy_score(y_deploy, y_pred_gbm))\n",
    "print(\"The accuracy of Xgboost:      \\t\", metrics.accuracy_score(y_deploy, y_pred_xgboost))\n",
    "print(\"The accuracy of NN:           \\t\", metrics.accuracy_score(y_deploy, y_pred_NN))\n",
    "print(\"The accuracy of NN2.5R:       \\t\", metrics.accuracy_score(y_deploy, y_pred_NN1))\n",
    "print(\"The accuracy of NN7.5R:       \\t\", metrics.accuracy_score(y_deploy, y_pred_NN2))\n",
    "print(\"The accuracy of NN65R:        \\t\", metrics.accuracy_score(y_deploy, y_pred_NN3))\n",
    "print(\"The accuracy of NN85R:        \\t\", metrics.accuracy_score(y_deploy, y_pred_NN4))\n",
    "print(\"The accuracy of UCB1 NN20R:    \\t\", metrics.accuracy_score(y_deploy, y_pred_NN1))\n",
    "print(\"The accuracy of E GREEDY  :    \\t\", metrics.accuracy_score(y_deploy, y_pred_EG))\n",
    "print(\"The accuracy of A e Greegy:    \\t\", metrics.accuracy_score(y_deploy, y_pred_AEG))\n",
    "print(\"The accuracy of SOFTMAX :      \\t\", metrics.accuracy_score(y_deploy, y_pred_SM))\n",
    "print(\"The accuracy of A SOFTMAX:     \\t\", metrics.accuracy_score(y_deploy, y_pred_ASM))\n",
    "print(\"The accuracy of THOMPSON SAM.: \\t\", metrics.accuracy_score(y_deploy, y_pred_TS))\n",
    "print(\"The accuracy of HEDGE:         \\t\", metrics.accuracy_score(y_deploy, y_pred_HG))\n",
    "print(\"The accuracy of EXP3 :         \\t\", metrics.accuracy_score(y_deploy, y_pred_EXP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Precision of the models on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Precision of KNN:          \\t\", metrics.precision_score(y_deploy, y_pred_neigh))\n",
    "print(\"Precision of LSVM:         \\t\", metrics.precision_score(y_deploy, y_pred_svm_linear))\n",
    "print(\"Precision of SVM:          \\t\", metrics.precision_score(y_deploy, y_pred_svm))\n",
    "print(\"Precision of DT_gini:      \\t\", metrics.precision_score(y_deploy, y_pred_gtgini))\n",
    "print(\"Precision of DT_entorpy:   \\t\", metrics.precision_score(y_deploy, y_pred_dt_IG))\n",
    "print(\"Precision of Bagging Knn:  \\t\", metrics.precision_score(y_deploy, y_pred_dt_BGKN))\n",
    "print(\"Precision of Bagging DT:   \\t\", metrics.precision_score(y_deploy, y_pred_dt_BGDT))\n",
    "print(\"Precision of Random Forest:\\t\", metrics.precision_score(y_deploy, y_pred_dt_RF))\n",
    "print(\"Precision of Ada Boost:    \\t\", metrics.precision_score(y_deploy, y_pred_dt_AD))\n",
    "print(\"Precision of Naive Bayes:  \\t\", metrics.precision_score(y_deploy, y_pred_NB))\n",
    "print(\"Precision of LDA:          \\t\", metrics.precision_score(y_deploy, y_pred_dt_LDA))\n",
    "print(\"Precision of QDA:          \\t\", metrics.precision_score(y_deploy, y_pred_dt_QDA))\n",
    "print(\"Precision of Log. Reg.:    \\t\", metrics.precision_score(y_deploy, y_pred_LR))\n",
    "print(\"Precision of GP CLASSI. :  \\t\", metrics.precision_score(y_deploy, y_pred_GP))\n",
    "print(\"Precision of LightGBM:     \\t\", metrics.precision_score(y_deploy, y_pred_gbm))\n",
    "print(\"Precision of Xgboost:      \\t\", metrics.precision_score(y_deploy, y_pred_xgboost))\n",
    "print(\"Precision of NN:           \\t\", metrics.precision_score(y_deploy, y_pred_NN))\n",
    "print(\"Precision of NN2.5R:       \\t\", metrics.precision_score(y_deploy, y_pred_NN1))\n",
    "print(\"Precision of NN7.5R:       \\t\", metrics.precision_score(y_deploy, y_pred_NN2))\n",
    "print(\"Precision of NN65R:        \\t\", metrics.precision_score(y_deploy, y_pred_NN3))\n",
    "print(\"Precision of NN85R:        \\t\", metrics.precision_score(y_deploy, y_pred_NN4))\n",
    "print(\"Precision of UCB1 NN20R:    \\t\", metrics.precision_score(y_deploy, y_pred_NN1))\n",
    "print(\"Precision of E GREEDY  :    \\t\", metrics.precision_score(y_deploy, y_pred_EG))\n",
    "print(\"Precision of A e Greegy:    \\t\", metrics.precision_score(y_deploy, y_pred_AEG))\n",
    "print(\"Precision of SOFTMAX :      \\t\", metrics.precision_score(y_deploy, y_pred_SM))\n",
    "print(\"Precision of A SOFTMAX:     \\t\", metrics.precision_score(y_deploy, y_pred_ASM))\n",
    "print(\"Precision of THOMPSON SAM.: \\t\", metrics.precision_score(y_deploy, y_pred_TS))\n",
    "print(\"Precision of HEDGE:         \\t\", metrics.precision_score(y_deploy, y_pred_HG))\n",
    "print(\"Precision of EXP3 :         \\t\", metrics.precision_score(y_deploy, y_pred_EXP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall of the models on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Recall of KNN :         \\t\", metrics.recall_score(y_deploy, y_pred_neigh))\n",
    "print(\"Recall of LSVM :        \\t\", metrics.recall_score(y_deploy, y_pred_svm_linear))\n",
    "print(\"Recall of SVM :         \\t\", metrics.recall_score(y_deploy, y_pred_svm))\n",
    "print(\"Recall of DT_gini :     \\t\", metrics.recall_score(y_deploy, y_pred_gtgini))\n",
    "print(\"Recall of DT_entorpy:   \\t\", metrics.recall_score(y_deploy, y_pred_dt_IG))\n",
    "print(\"Recall of Bagging Knn : \\t\", metrics.recall_score(y_deploy, y_pred_dt_BGKN))\n",
    "print(\"Recall of Bagging DT :  \\t\", metrics.recall_score(y_deploy, y_pred_dt_BGDT))\n",
    "print(\"Recall of Random Forest:\\t\", metrics.recall_score(y_deploy, y_pred_dt_RF))\n",
    "print(\"Recall of Ada Boost :   \\t\", metrics.recall_score(y_deploy, y_pred_dt_AD))\n",
    "print(\"Recall of Naive Bayes : \\t\", metrics.recall_score(y_deploy, y_pred_NB))\n",
    "print(\"Recall of LDA :         \\t\", metrics.recall_score(y_deploy, y_pred_dt_LDA))\n",
    "print(\"Recall of QDA :         \\t\", metrics.recall_score(y_deploy, y_pred_dt_QDA))\n",
    "print(\"Recall of Log. Reg.:    \\t\", metrics.recall_score(y_deploy, y_pred_LR))\n",
    "print(\"Recall of GP CLASSI. :  \\t\", metrics.recall_score(y_deploy, y_pred_GP))\n",
    "print(\"Recall of LightGBM:     \\t\", metrics.recall_score(y_deploy, y_pred_gbm))\n",
    "print(\"Recall of Xgboost:      \\t\", metrics.recall_score(y_deploy, y_pred_xgboost))\n",
    "print(\"Recall of NN :          \\t\", metrics.recall_score(y_deploy, y_pred_NN))\n",
    "print(\"Recall of NN2.5R:       \\t\", metrics.recall_score(y_deploy, y_pred_NN1))\n",
    "print(\"Recall of NN7.5R:       \\t\", metrics.recall_score(y_deploy, y_pred_NN2))\n",
    "print(\"Recall of NN65R:        \\t\", metrics.recall_score(y_deploy, y_pred_NN3))\n",
    "print(\"Recall of NN85R:        \\t\", metrics.recall_score(y_deploy, y_pred_NN4))\n",
    "print(\"Recall of UCB1 NN20R:    \\t\", metrics.recall_score(y_deploy, y_pred_NN1))\n",
    "print(\"Recall of E GREEDY  :    \\t\", metrics.recall_score(y_deploy, y_pred_EG))\n",
    "print(\"Recall of A e Greegy:    \\t\", metrics.recall_score(y_deploy, y_pred_AEG))\n",
    "print(\"Recall of SOFTMAX :      \\t\", metrics.recall_score(y_deploy, y_pred_SM))\n",
    "print(\"Recall of A SOFTMAX:     \\t\", metrics.recall_score(y_deploy, y_pred_ASM))\n",
    "print(\"Recall of THOMPSON SAM.: \\t\", metrics.recall_score(y_deploy, y_pred_TS))\n",
    "print(\"Recall of HEDGE:         \\t\", metrics.recall_score(y_deploy, y_pred_HG))\n",
    "print(\"Recall of EXP3 :         \\t\", metrics.recall_score(y_deploy, y_pred_EXP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 score of the models on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"F1 score of KNN:          \\t\", metrics.f1_score(y_deploy, y_pred_neigh))\n",
    "print(\"F1 score of LSVM:         \\t\", metrics.f1_score(y_deploy, y_pred_svm_linear))\n",
    "print(\"F1 score of SVM:          \\t\", metrics.f1_score(y_deploy, y_pred_svm))\n",
    "print(\"F1 score of DT_gini:      \\t\", metrics.f1_score(y_deploy, y_pred_gtgini))\n",
    "print(\"F1 score of DT_entorpy:   \\t\", metrics.f1_score(y_deploy, y_pred_dt_IG))\n",
    "print(\"F1 score of Bagging Knn:  \\t\", metrics.f1_score(y_deploy, y_pred_dt_BGKN))\n",
    "print(\"F1 score of Bagging DT:   \\t\", metrics.f1_score(y_deploy, y_pred_dt_BGDT))\n",
    "print(\"F1 score of Random Forest:\\t\", metrics.f1_score(y_deploy, y_pred_dt_RF))\n",
    "print(\"F1 score of Ada Boost:    \\t\", metrics.f1_score(y_deploy, y_pred_dt_AD))\n",
    "print(\"F1 score of Naive Bayes:  \\t\", metrics.f1_score(y_deploy, y_pred_NB))\n",
    "print(\"F1 score of LDA:          \\t\", metrics.f1_score(y_deploy, y_pred_dt_LDA))\n",
    "print(\"F1 score of QDA:          \\t\", metrics.f1_score(y_deploy, y_pred_dt_QDA))\n",
    "print(\"F1 score of Log. Reg.:    \\t\", metrics.f1_score(y_deploy, y_pred_LR))\n",
    "print(\"F1 score of GP CLASSI. :  \\t\", metrics.f1_score(y_deploy, y_pred_GP))\n",
    "print(\"F1 score of LightGBM:     \\t\", metrics.f1_score(y_deploy, y_pred_gbm))\n",
    "print(\"F1 score of Xgboost:      \\t\", metrics.f1_score(y_deploy, y_pred_xgboost))\n",
    "print(\"F1 score of NN:           \\t\", metrics.f1_score(y_deploy, y_pred_NN))\n",
    "print(\"F1 score of NN2.5R:       \\t\", metrics.f1_score(y_deploy, y_pred_NN1))\n",
    "print(\"F1 score of NN7.5R:       \\t\", metrics.f1_score(y_deploy, y_pred_NN2))\n",
    "print(\"F1 score of NN65R:        \\t\", metrics.f1_score(y_deploy, y_pred_NN3))\n",
    "print(\"F1 score of NN85R:        \\t\", metrics.f1_score(y_deploy, y_pred_NN4))\n",
    "print(\"F1 score of UCB1 NN20R:    \\t\", metrics.f1_score(y_deploy, y_pred_NN1))\n",
    "print(\"F1 score of E GREEDY  :    \\t\", metrics.f1_score(y_deploy, y_pred_EG))\n",
    "print(\"F1 score of A e Greegy:    \\t\", metrics.f1_score(y_deploy, y_pred_AEG))\n",
    "print(\"F1 score of SOFTMAX :      \\t\", metrics.f1_score(y_deploy, y_pred_SM))\n",
    "print(\"F1 score of A SOFTMAX:     \\t\", metrics.f1_score(y_deploy, y_pred_ASM))\n",
    "print(\"F1 score of THOMPSON SAM.: \\t\", metrics.f1_score(y_deploy, y_pred_TS))\n",
    "print(\"F1 score of HEDGE:         \\t\", metrics.f1_score(y_deploy, y_pred_HG))\n",
    "print(\"F1 score of EXP3 :         \\t\", metrics.f1_score(y_deploy, y_pred_EXP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Plot the results Comparing to UCB1 three times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "accData = [metrics.accuracy_score(y_deploy, y_pred_neigh),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm_linear), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_gtgini),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_IG), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGKN),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGDT), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_RF),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_AD), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_NB),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_LDA), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_QDA),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_NN),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_NN1),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_NN2),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_NN3),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_NN4)]\n",
    "PresionData = [metrics.precision_score(y_deploy, y_pred_neigh),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm_linear),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm),\n",
    "               metrics.precision_score(y_deploy, y_pred_gtgini),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_IG),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGKN),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGDT),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_RF),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_AD),\n",
    "               metrics.precision_score(y_deploy, y_pred_NB),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_LDA),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_QDA),\n",
    "               metrics.precision_score(y_deploy, y_pred_NN),\n",
    "               metrics.precision_score(y_deploy, y_pred_NN1),\n",
    "               metrics.precision_score(y_deploy, y_pred_NN2),\n",
    "               metrics.precision_score(y_deploy, y_pred_NN3),\n",
    "               metrics.precision_score(y_deploy, y_pred_NN4)]\n",
    "RecallData = [ metrics.recall_score(y_deploy, y_pred_neigh),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm_linear),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm),\n",
    "              metrics.recall_score(y_deploy, y_pred_gtgini),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_IG),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGKN),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGDT),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_RF),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_AD),\n",
    "              metrics.recall_score(y_deploy, y_pred_NB),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_LDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_QDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_NN),\n",
    "              metrics.recall_score(y_deploy, y_pred_NN1),\n",
    "              metrics.recall_score(y_deploy, y_pred_NN2),\n",
    "              metrics.recall_score(y_deploy, y_pred_NN3),\n",
    "              metrics.recall_score(y_deploy, y_pred_NN4)]\n",
    "F1Data = [metrics.f1_score(y_deploy, y_pred_neigh),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm_linear),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm),\n",
    "          metrics.f1_score(y_deploy, y_pred_gtgini),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_IG),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGKN),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGDT),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_RF),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_AD),\n",
    "          metrics.f1_score(y_deploy, y_pred_NB),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_LDA),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_QDA),\n",
    "          metrics.f1_score(y_deploy, y_pred_NN),\n",
    "          metrics.f1_score(y_deploy, y_pred_NN1),\n",
    "          metrics.f1_score(y_deploy, y_pred_NN2),\n",
    "          metrics.f1_score(y_deploy, y_pred_NN3),\n",
    "          metrics.f1_score(y_deploy, y_pred_NN4)]\n",
    "N = len(accData)\n",
    "## necessary variables\n",
    "ind = np.arange(N)                # the x locations for the groups\n",
    "width = 0.15                     # the width of the bars\n",
    "## the bars\n",
    "rects1 = ax.bar(ind, accData, width,\n",
    "                color='black',\n",
    "                #yerr=menStd,\n",
    "                error_kw=dict(elinewidth=2,ecolor='red'))\n",
    "rects2 = ax.bar(ind+width, F1Data, width,\n",
    "                    color='red',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='black'))\n",
    "rects3 = ax.bar(ind+width+width, PresionData, width,\n",
    "                    color='green',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='blue'))\n",
    "rects4 = ax.bar(ind+width+width+width, RecallData, width,\n",
    "                    color='blue',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='green'))\n",
    "# axes and labels\n",
    "ax.set_xlim(-width,len(ind)+width)\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Scores of different classifiers on Test Data')\n",
    "xTickMarks = ['Knn', 'LSVM', 'SVM', 'DT_gini', 'DT_entorpy' ,\n",
    "              'Bagging Knn' , 'Bagging DT' , 'Random Forest' , 'Ada Boost' ,\n",
    "              'NB' , 'LDA' , 'QDA' , 'NN', 'NN2.5%R' , 'NN7.5%R' , 'NN65%R' , 'NN85%R']\n",
    "ax.set_xticks(ind+width)\n",
    "xtickNames = ax.set_xticklabels(xTickMarks)\n",
    "plt.setp(xtickNames, rotation=45, fontsize=10)\n",
    "\n",
    "\n",
    "\n",
    "## add a legend\n",
    "ax.legend( (rects1[0], rects2[0], rects3[0], rects4[0]), ('Acc.', 'F1' , 'Prec.' , 'Recall') , loc=8, fancybox=True, \n",
    "          frameon=True, shadow=True)\n",
    "ax.set_facecolor('0.9')\n",
    "\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "\n",
    "ax.spines['top'].set_linewidth(0.9)\n",
    "ax.spines['right'].set_linewidth(0.9)\n",
    "ax.spines['bottom'].set_linewidth(0.9)\n",
    "ax.spines['left'].set_linewidth(0.9)\n",
    "ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import pi\n",
    "from bokeh.charts import Bar, Area, defaults\n",
    "from bokeh.layouts import row\n",
    "from bokeh.charts.attributes import cat, color\n",
    "from bokeh.charts.operations import blend\n",
    "#from bokeh.charts.utils import df_from_json\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "############################################################################################################\n",
    "TOOLS = 'box_zoom,box_select,crosshair,resize,reset,lasso_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "#defaults.width = 1000\n",
    "#defaults.height = 800\n",
    "output_notebook()\n",
    "df1 = pd.DataFrame({'Matric': xTickMarks,\n",
    "                    'Accuracy':accData, \n",
    "                   'Precision': PresionData, \n",
    "                   'Recall': RecallData, \n",
    "                    'F1 Score': F1Data})\n",
    "############################################################################################################\n",
    "bar = Bar(df1,\n",
    "          values=blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "          label=cat(columns='Matric', sort=False),\n",
    "          stack=cat(columns='Score', sort=False),\n",
    "          color=color(columns='Score', palette=['SaddleBrown', 'Silver', 'Goldenrod', 'Grey'],\n",
    "                      sort=False),\n",
    "          legend='bottom_center', xlabel=\"List of Models\", ylabel=\"The Scores\",\n",
    "          title=\"Scores of different Models\", \n",
    "          tooltips=[('Score', '@Score'), ('Model', '@Matric')],\n",
    "          tools=TOOLS, plot_width=900, plot_height=800)\n",
    "bar.title.align = \"center\"\n",
    "bar.xaxis.major_label_orientation = pi/2\n",
    "###############################################################################################################\n",
    "p = Bar(df1, label='Matric', \n",
    "        values = blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "        group=cat(columns='Score', sort=False),\n",
    "        title=\"Scores of different Models\", legend='bottom_center',\n",
    "       tools=TOOLS, plot_width=900, plot_height=600,\n",
    "       xlabel='List of Models', ylabel='The Scores')\n",
    "p.title.align = \"center\"\n",
    "#p.yaxis.major_label_orientation = \"vertical\"\n",
    "p.xaxis.major_label_orientation = pi/2\n",
    "#########################################################################################################\n",
    "data = dict(\n",
    "    Acc = accData,\n",
    "    Pre = PresionData,\n",
    "    Rec = RecallData,\n",
    "    F1 = F1Data,\n",
    ")\n",
    "area1 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area1.title.align = \"center\"\n",
    "area2 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             stack=True, xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area2.title.align = \"center\"\n",
    "#########################################################################################################\n",
    "show(bar)\n",
    "show(p)\n",
    "#show(area1)\n",
    "#show(area2)\n",
    "show(row(area1, area2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare All the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "accData = [metrics.accuracy_score(y_deploy, y_pred_neigh),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm_linear), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_gtgini),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_IG), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGKN),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGDT), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_RF),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_AD), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_NB),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_LDA), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_QDA),           \n",
    "           metrics.accuracy_score(y_deploy, y_pred_LR),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_GP),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_gbm),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_xgboost),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_NN),        \n",
    "           metrics.accuracy_score(y_deploy, y_pred_NN1),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_EG),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_AEG),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_SM),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_ASM),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_TS),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_HG),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_EXP)]\n",
    "          \n",
    "PresionData = [metrics.precision_score(y_deploy, y_pred_neigh),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm_linear),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm),\n",
    "               metrics.precision_score(y_deploy, y_pred_gtgini),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_IG),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGKN),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGDT),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_RF),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_AD),\n",
    "               metrics.precision_score(y_deploy, y_pred_NB),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_LDA),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_QDA),              \n",
    "               metrics.precision_score(y_deploy, y_pred_LR),\n",
    "               metrics.precision_score(y_deploy, y_pred_GP),\n",
    "               metrics.precision_score(y_deploy, y_pred_gbm),\n",
    "               metrics.precision_score(y_deploy, y_pred_xgboost),\n",
    "               metrics.precision_score(y_deploy, y_pred_NN),\n",
    "               metrics.precision_score(y_deploy, y_pred_NN1),\n",
    "               metrics.precision_score(y_deploy, y_pred_EG),\n",
    "               metrics.precision_score(y_deploy, y_pred_AEG),\n",
    "               metrics.precision_score(y_deploy, y_pred_SM),\n",
    "               metrics.precision_score(y_deploy, y_pred_ASM),\n",
    "               metrics.precision_score(y_deploy, y_pred_TS),\n",
    "               metrics.precision_score(y_deploy, y_pred_HG),\n",
    "               metrics.precision_score(y_deploy, y_pred_EXP)]\n",
    "RecallData = [ metrics.recall_score(y_deploy, y_pred_neigh),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm_linear),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm),\n",
    "              metrics.recall_score(y_deploy, y_pred_gtgini),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_IG),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGKN),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGDT),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_RF),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_AD),\n",
    "              metrics.recall_score(y_deploy, y_pred_NB),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_LDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_QDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_LR),\n",
    "              metrics.recall_score(y_deploy, y_pred_GP),\n",
    "              metrics.recall_score(y_deploy, y_pred_gbm),\n",
    "              metrics.recall_score(y_deploy, y_pred_xgboost),       \n",
    "              metrics.recall_score(y_deploy, y_pred_NN),\n",
    "              metrics.recall_score(y_deploy, y_pred_NN1),\n",
    "              metrics.recall_score(y_deploy, y_pred_AEG),\n",
    "              metrics.recall_score(y_deploy, y_pred_EG),\n",
    "              metrics.recall_score(y_deploy, y_pred_SM),\n",
    "              metrics.recall_score(y_deploy, y_pred_ASM),\n",
    "              metrics.recall_score(y_deploy, y_pred_TS),\n",
    "              metrics.recall_score(y_deploy, y_pred_HG),\n",
    "              metrics.recall_score(y_deploy, y_pred_EXP)]\n",
    "F1Data = [metrics.f1_score(y_deploy, y_pred_neigh),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm_linear),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm),\n",
    "          metrics.f1_score(y_deploy, y_pred_gtgini),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_IG),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGKN),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGDT),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_RF),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_AD),\n",
    "          metrics.f1_score(y_deploy, y_pred_NB),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_LDA),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_QDA),         \n",
    "          metrics.f1_score(y_deploy, y_pred_LR),\n",
    "          metrics.f1_score(y_deploy, y_pred_GP),\n",
    "          metrics.f1_score(y_deploy, y_pred_gbm),\n",
    "          metrics.f1_score(y_deploy, y_pred_xgboost),\n",
    "          metrics.f1_score(y_deploy, y_pred_NN),                             \n",
    "          metrics.f1_score(y_deploy, y_pred_NN1),\n",
    "          metrics.f1_score(y_deploy, y_pred_EG),\n",
    "          metrics.f1_score(y_deploy, y_pred_AEG),\n",
    "          metrics.f1_score(y_deploy, y_pred_SM),\n",
    "          metrics.f1_score(y_deploy, y_pred_ASM),\n",
    "          metrics.f1_score(y_deploy, y_pred_TS),\n",
    "          metrics.f1_score(y_deploy, y_pred_HG),\n",
    "          metrics.f1_score(y_deploy, y_pred_EXP)]         \n",
    "\n",
    "\n",
    "\n",
    "N = len(accData)\n",
    "## necessary variables\n",
    "ind = np.arange(N)                # the x locations for the groups\n",
    "width = 0.17                     # the width of the bars\n",
    "## the bars\n",
    "rects1 = ax.bar(ind, accData, width,\n",
    "                color='black',\n",
    "                #yerr=menStd,\n",
    "                error_kw=dict(elinewidth=2,ecolor='red'))\n",
    "rects2 = ax.bar(ind+width, F1Data, width,\n",
    "                    color='red',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='black'))\n",
    "rects3 = ax.bar(ind+width+width, PresionData, width,\n",
    "                    color='green',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='blue'))\n",
    "rects4 = ax.bar(ind+width+width+width, RecallData, width,\n",
    "                    color='blue',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='green'))\n",
    "# axes and labels\n",
    "ax.set_xlim(-width,len(ind)+width)\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Name of Classifier')\n",
    "ax.set_title('Scores of different classifiers on Test Data')\n",
    "xTickMarks = ['Knn', 'LSVM', 'SVM', 'DT_gini', 'DT_entorpy' ,\n",
    "              'Bagging Knn' , 'Bagging DT' , 'Random Forest' , 'Ada Boost' ,\n",
    "              'NB' , 'LDA' , 'QDA' ,'Log. Reg.' ,'GP Class.','LightGBM','Xgboost',\n",
    "              'NN', 'UCB1' , 'E Greedy' , 'Decay E Gr.' , 'Softmax', 'Decay SM',\n",
    "               'Tomp. Sampling', 'Hedge', 'EXP3']\n",
    "ax.set_xticks(ind+width)\n",
    "xtickNames = ax.set_xticklabels(xTickMarks)\n",
    "plt.setp(xtickNames, rotation=90, fontsize=10)\n",
    "## add a legend\n",
    "ax.legend( (rects1[0], rects2[0], rects3[0], rects4[0]), ('Acc.', 'F1' , 'Prec.' , 'Recall') , loc=8, fancybox=True, \n",
    "          frameon=True, shadow=True)\n",
    "ax.set_facecolor('0.9')\n",
    "\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "\n",
    "ax.spines['top'].set_linewidth(0.9)\n",
    "ax.spines['right'].set_linewidth(0.9)\n",
    "ax.spines['bottom'].set_linewidth(0.9)\n",
    "ax.spines['left'].set_linewidth(0.9)\n",
    "ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import pi\n",
    "from bokeh.charts import Bar, Area, defaults\n",
    "from bokeh.layouts import row\n",
    "from bokeh.charts.attributes import cat, color\n",
    "from bokeh.charts.operations import blend\n",
    "#from bokeh.charts.utils import df_from_json\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "############################################################################################################\n",
    "TOOLS = 'box_zoom,box_select,crosshair,resize,reset,lasso_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "#defaults.width = 1000\n",
    "#defaults.height = 800\n",
    "output_notebook()\n",
    "df1 = pd.DataFrame({'Matric': xTickMarks,\n",
    "                    'Accuracy':accData, \n",
    "                   'Precision': PresionData, \n",
    "                   'Recall': RecallData, \n",
    "                    'F1 Score': F1Data})\n",
    "############################################################################################################\n",
    "bar = Bar(df1,\n",
    "          values=blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "          label=cat(columns='Matric', sort=False),\n",
    "          stack=cat(columns='Score', sort=False),\n",
    "          color=color(columns='Score', palette=['SaddleBrown', 'Silver', 'Goldenrod', 'Grey'],\n",
    "                      sort=False),\n",
    "          legend='bottom_center', xlabel=\"List of Models\", ylabel=\"The Scores\",\n",
    "          title=\"Scores of different Models\", \n",
    "          tooltips=[('Score', '@Score'), ('Model', '@Matric')],\n",
    "          tools=TOOLS, plot_width=900, plot_height=800)\n",
    "bar.title.align = \"center\"\n",
    "bar.xaxis.major_label_orientation = pi/2\n",
    "###############################################################################################################\n",
    "p = Bar(df1, label='Matric', \n",
    "        values = blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "        group=cat(columns='Score', sort=False),\n",
    "        title=\"Scores of different Models\", legend='bottom_center',\n",
    "       tools=TOOLS, plot_width=900, plot_height=600,\n",
    "       xlabel='List of Models', ylabel='The Scores')\n",
    "p.title.align = \"center\"\n",
    "#p.yaxis.major_label_orientation = \"vertical\"\n",
    "p.xaxis.major_label_orientation = pi/2\n",
    "#########################################################################################################\n",
    "data = dict(\n",
    "    Acc = accData,\n",
    "    Pre = PresionData,\n",
    "    Rec = RecallData,\n",
    "    F1 = F1Data,\n",
    ")\n",
    "area1 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area1.title.align = \"center\"\n",
    "area2 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             stack=True, xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area2.title.align = \"center\"\n",
    "#########################################################################################################\n",
    "show(bar)\n",
    "show(p)\n",
    "#show(area1)\n",
    "#show(area2)\n",
    "show(row(area1, area2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare UCB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "accData = [metrics.accuracy_score(y_deploy, y_pred_neigh),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm_linear), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_gtgini),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_IG), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGKN),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGDT), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_RF),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_AD), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_NB),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_LDA), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_QDA),           \n",
    "           metrics.accuracy_score(y_deploy, y_pred_LR),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_GP),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_gbm),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_xgboost),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_NN),        \n",
    "           metrics.accuracy_score(y_deploy, y_pred_NN1)]\n",
    "          \n",
    "PresionData = [metrics.precision_score(y_deploy, y_pred_neigh),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm_linear),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm),\n",
    "               metrics.precision_score(y_deploy, y_pred_gtgini),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_IG),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGKN),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGDT),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_RF),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_AD),\n",
    "               metrics.precision_score(y_deploy, y_pred_NB),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_LDA),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_QDA),              \n",
    "               metrics.precision_score(y_deploy, y_pred_LR),\n",
    "               metrics.precision_score(y_deploy, y_pred_GP),\n",
    "               metrics.precision_score(y_deploy, y_pred_gbm),\n",
    "               metrics.precision_score(y_deploy, y_pred_xgboost),\n",
    "               metrics.precision_score(y_deploy, y_pred_NN),\n",
    "               metrics.precision_score(y_deploy, y_pred_NN1)]\n",
    "\n",
    "RecallData = [ metrics.recall_score(y_deploy, y_pred_neigh),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm_linear),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm),\n",
    "              metrics.recall_score(y_deploy, y_pred_gtgini),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_IG),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGKN),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGDT),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_RF),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_AD),\n",
    "              metrics.recall_score(y_deploy, y_pred_NB),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_LDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_QDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_LR),\n",
    "              metrics.recall_score(y_deploy, y_pred_GP),\n",
    "              metrics.recall_score(y_deploy, y_pred_gbm),\n",
    "              metrics.recall_score(y_deploy, y_pred_xgboost),       \n",
    "              metrics.recall_score(y_deploy, y_pred_NN),\n",
    "              metrics.recall_score(y_deploy, y_pred_NN1)]\n",
    "\n",
    "F1Data = [metrics.f1_score(y_deploy, y_pred_neigh),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm_linear),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm),\n",
    "          metrics.f1_score(y_deploy, y_pred_gtgini),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_IG),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGKN),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGDT),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_RF),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_AD),\n",
    "          metrics.f1_score(y_deploy, y_pred_NB),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_LDA),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_QDA),         \n",
    "          metrics.f1_score(y_deploy, y_pred_LR),\n",
    "          metrics.f1_score(y_deploy, y_pred_GP),\n",
    "          metrics.f1_score(y_deploy, y_pred_gbm),\n",
    "          metrics.f1_score(y_deploy, y_pred_xgboost),\n",
    "          metrics.f1_score(y_deploy, y_pred_NN),                             \n",
    "          metrics.f1_score(y_deploy, y_pred_NN1)]         \n",
    "\n",
    "\n",
    "\n",
    "N = len(accData)\n",
    "## necessary variables\n",
    "ind = np.arange(N)                # the x locations for the groups\n",
    "width = 0.17                     # the width of the bars\n",
    "## the bars\n",
    "rects1 = ax.bar(ind, accData, width,\n",
    "                color='black',\n",
    "                #yerr=menStd,\n",
    "                error_kw=dict(elinewidth=2,ecolor='red'))\n",
    "rects2 = ax.bar(ind+width, F1Data, width,\n",
    "                    color='red',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='black'))\n",
    "rects3 = ax.bar(ind+width+width, PresionData, width,\n",
    "                    color='green',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='blue'))\n",
    "rects4 = ax.bar(ind+width+width+width, RecallData, width,\n",
    "                    color='blue',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='green'))\n",
    "# axes and labels\n",
    "ax.set_xlim(-width,len(ind)+width)\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Name of Classifier')\n",
    "ax.set_title('Scores of different classifiers on Test Data')\n",
    "xTickMarks = ['Knn', 'LSVM', 'SVM', 'DT_gini', 'DT_entorpy' ,\n",
    "              'Bagging Knn' , 'Bagging DT' , 'Random Forest' , 'Ada Boost' ,\n",
    "              'NB' , 'LDA' , 'QDA' ,'Log. Reg.' ,'GP Class.','LightGBM','Xgboost',\n",
    "              'NN', 'UCB1']\n",
    "ax.set_xticks(ind+width)\n",
    "xtickNames = ax.set_xticklabels(xTickMarks)\n",
    "plt.setp(xtickNames, rotation=90, fontsize=10)\n",
    "## add a legend\n",
    "ax.legend( (rects1[0], rects2[0], rects3[0], rects4[0]), ('Acc.', 'F1' , 'Prec.' , 'Recall') , loc=8, fancybox=True, \n",
    "          frameon=True, shadow=True)\n",
    "ax.set_facecolor('0.9')\n",
    "\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "\n",
    "ax.spines['top'].set_linewidth(0.9)\n",
    "ax.spines['right'].set_linewidth(0.9)\n",
    "ax.spines['bottom'].set_linewidth(0.9)\n",
    "ax.spines['left'].set_linewidth(0.9)\n",
    "ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import pi\n",
    "from bokeh.charts import Bar, Area, defaults\n",
    "from bokeh.layouts import row\n",
    "from bokeh.charts.attributes import cat, color\n",
    "from bokeh.charts.operations import blend\n",
    "#from bokeh.charts.utils import df_from_json\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "############################################################################################################\n",
    "TOOLS = 'box_zoom,box_select,crosshair,resize,reset,lasso_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "#defaults.width = 1000\n",
    "#defaults.height = 800\n",
    "output_notebook()\n",
    "df1 = pd.DataFrame({'Matric': xTickMarks,\n",
    "                    'Accuracy':accData, \n",
    "                   'Precision': PresionData, \n",
    "                   'Recall': RecallData, \n",
    "                    'F1 Score': F1Data})\n",
    "############################################################################################################\n",
    "bar = Bar(df1,\n",
    "          values=blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "          label=cat(columns='Matric', sort=False),\n",
    "          stack=cat(columns='Score', sort=False),\n",
    "          color=color(columns='Score', palette=['SaddleBrown', 'Silver', 'Goldenrod', 'Grey'],\n",
    "                      sort=False),\n",
    "          legend='bottom_center', xlabel=\"List of Models\", ylabel=\"The Scores\",\n",
    "          title=\"Scores of different Models\", \n",
    "          tooltips=[('Score', '@Score'), ('Model', '@Matric')],\n",
    "          tools=TOOLS, plot_width=900, plot_height=800)\n",
    "bar.title.align = \"center\"\n",
    "bar.xaxis.major_label_orientation = pi/2\n",
    "###############################################################################################################\n",
    "p = Bar(df1, label='Matric', \n",
    "        values = blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "        group=cat(columns='Score', sort=False),\n",
    "        title=\"Scores of different Models\", legend='bottom_center',\n",
    "       tools=TOOLS, plot_width=900, plot_height=600,\n",
    "       xlabel='List of Models', ylabel='The Scores')\n",
    "p.title.align = \"center\"\n",
    "#p.yaxis.major_label_orientation = \"vertical\"\n",
    "p.xaxis.major_label_orientation = pi/2\n",
    "#########################################################################################################\n",
    "data = dict(\n",
    "    Acc = accData,\n",
    "    Pre = PresionData,\n",
    "    Rec = RecallData,\n",
    "    F1 = F1Data,\n",
    ")\n",
    "area1 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area1.title.align = \"center\"\n",
    "area2 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             stack=True, xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area2.title.align = \"center\"\n",
    "#########################################################################################################\n",
    "show(bar)\n",
    "show(p)\n",
    "#show(area1)\n",
    "#show(area2)\n",
    "show(row(area1, area2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Epsilon greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "accData = [metrics.accuracy_score(y_deploy, y_pred_neigh),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm_linear), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_gtgini),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_IG), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGKN),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGDT), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_RF),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_AD), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_NB),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_LDA), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_QDA),           \n",
    "           metrics.accuracy_score(y_deploy, y_pred_LR),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_GP),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_gbm),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_xgboost),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_NN),        \n",
    "           metrics.accuracy_score(y_deploy, y_pred_EG),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_AEG)]\n",
    "          \n",
    "PresionData = [metrics.precision_score(y_deploy, y_pred_neigh),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm_linear),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm),\n",
    "               metrics.precision_score(y_deploy, y_pred_gtgini),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_IG),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGKN),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGDT),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_RF),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_AD),\n",
    "               metrics.precision_score(y_deploy, y_pred_NB),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_LDA),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_QDA),              \n",
    "               metrics.precision_score(y_deploy, y_pred_LR),\n",
    "               metrics.precision_score(y_deploy, y_pred_GP),\n",
    "               metrics.precision_score(y_deploy, y_pred_gbm),\n",
    "               metrics.precision_score(y_deploy, y_pred_xgboost),\n",
    "               metrics.precision_score(y_deploy, y_pred_NN),\n",
    "               metrics.precision_score(y_deploy, y_pred_EG),\n",
    "               metrics.precision_score(y_deploy, y_pred_AEG)]\n",
    "\n",
    "RecallData = [ metrics.recall_score(y_deploy, y_pred_neigh),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm_linear),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm),\n",
    "              metrics.recall_score(y_deploy, y_pred_gtgini),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_IG),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGKN),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGDT),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_RF),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_AD),\n",
    "              metrics.recall_score(y_deploy, y_pred_NB),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_LDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_QDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_LR),\n",
    "              metrics.recall_score(y_deploy, y_pred_GP),\n",
    "              metrics.recall_score(y_deploy, y_pred_gbm),\n",
    "              metrics.recall_score(y_deploy, y_pred_xgboost),       \n",
    "              metrics.recall_score(y_deploy, y_pred_NN),\n",
    "              metrics.recall_score(y_deploy, y_pred_AEG),\n",
    "              metrics.recall_score(y_deploy, y_pred_EG)]\n",
    "\n",
    "F1Data = [metrics.f1_score(y_deploy, y_pred_neigh),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm_linear),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm),\n",
    "          metrics.f1_score(y_deploy, y_pred_gtgini),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_IG),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGKN),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGDT),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_RF),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_AD),\n",
    "          metrics.f1_score(y_deploy, y_pred_NB),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_LDA),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_QDA),         \n",
    "          metrics.f1_score(y_deploy, y_pred_LR),\n",
    "          metrics.f1_score(y_deploy, y_pred_GP),\n",
    "          metrics.f1_score(y_deploy, y_pred_gbm),\n",
    "          metrics.f1_score(y_deploy, y_pred_xgboost),\n",
    "          metrics.f1_score(y_deploy, y_pred_NN),                             \n",
    "          metrics.f1_score(y_deploy, y_pred_EG),\n",
    "          metrics.f1_score(y_deploy, y_pred_AEG)]         \n",
    "\n",
    "\n",
    "\n",
    "N = len(accData)\n",
    "## necessary variables\n",
    "ind = np.arange(N)                # the x locations for the groups\n",
    "width = 0.17                     # the width of the bars\n",
    "## the bars\n",
    "rects1 = ax.bar(ind, accData, width,\n",
    "                color='black',\n",
    "                #yerr=menStd,\n",
    "                error_kw=dict(elinewidth=2,ecolor='red'))\n",
    "rects2 = ax.bar(ind+width, F1Data, width,\n",
    "                    color='red',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='black'))\n",
    "rects3 = ax.bar(ind+width+width, PresionData, width,\n",
    "                    color='green',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='blue'))\n",
    "rects4 = ax.bar(ind+width+width+width, RecallData, width,\n",
    "                    color='blue',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='green'))\n",
    "# axes and labels\n",
    "ax.set_xlim(-width,len(ind)+width)\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Name of Classifier')\n",
    "ax.set_title('Scores of different classifiers on Test Data')\n",
    "xTickMarks = ['Knn', 'LSVM', 'SVM', 'DT_gini', 'DT_entorpy' ,\n",
    "              'Bagging Knn' , 'Bagging DT' , 'Random Forest' , 'Ada Boost' ,\n",
    "              'NB' , 'LDA' , 'QDA' ,'Log. Reg.' ,'GP Class.','LightGBM','Xgboost',\n",
    "              'NN',  'E Greedy' , 'Decay E Gr.' ]\n",
    "ax.set_xticks(ind+width)\n",
    "xtickNames = ax.set_xticklabels(xTickMarks)\n",
    "plt.setp(xtickNames, rotation=90, fontsize=10)\n",
    "## add a legend\n",
    "ax.legend( (rects1[0], rects2[0], rects3[0], rects4[0]), ('Acc.', 'F1' , 'Prec.' , 'Recall') , loc=8, fancybox=True, \n",
    "          frameon=True, shadow=True)\n",
    "ax.set_facecolor('0.9')\n",
    "\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "\n",
    "ax.spines['top'].set_linewidth(0.9)\n",
    "ax.spines['right'].set_linewidth(0.9)\n",
    "ax.spines['bottom'].set_linewidth(0.9)\n",
    "ax.spines['left'].set_linewidth(0.9)\n",
    "ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import pi\n",
    "from bokeh.charts import Bar, Area, defaults\n",
    "from bokeh.layouts import row\n",
    "from bokeh.charts.attributes import cat, color\n",
    "from bokeh.charts.operations import blend\n",
    "#from bokeh.charts.utils import df_from_json\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "############################################################################################################\n",
    "TOOLS = 'box_zoom,box_select,crosshair,resize,reset,lasso_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "#defaults.width = 1000\n",
    "#defaults.height = 800\n",
    "output_notebook()\n",
    "df1 = pd.DataFrame({'Matric': xTickMarks,\n",
    "                    'Accuracy':accData, \n",
    "                   'Precision': PresionData, \n",
    "                   'Recall': RecallData, \n",
    "                    'F1 Score': F1Data})\n",
    "############################################################################################################\n",
    "bar = Bar(df1,\n",
    "          values=blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "          label=cat(columns='Matric', sort=False),\n",
    "          stack=cat(columns='Score', sort=False),\n",
    "          color=color(columns='Score', palette=['SaddleBrown', 'Silver', 'Goldenrod', 'Grey'],\n",
    "                      sort=False),\n",
    "          legend='bottom_center', xlabel=\"List of Models\", ylabel=\"The Scores\",\n",
    "          title=\"Scores of different Models\", \n",
    "          tooltips=[('Score', '@Score'), ('Model', '@Matric')],\n",
    "          tools=TOOLS, plot_width=900, plot_height=800)\n",
    "bar.title.align = \"center\"\n",
    "bar.xaxis.major_label_orientation = pi/2\n",
    "###############################################################################################################\n",
    "p = Bar(df1, label='Matric', \n",
    "        values = blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "        group=cat(columns='Score', sort=False),\n",
    "        title=\"Scores of different Models\", legend='bottom_center',\n",
    "       tools=TOOLS, plot_width=900, plot_height=600,\n",
    "       xlabel='List of Models', ylabel='The Scores')\n",
    "p.title.align = \"center\"\n",
    "#p.yaxis.major_label_orientation = \"vertical\"\n",
    "p.xaxis.major_label_orientation = pi/2\n",
    "#########################################################################################################\n",
    "data = dict(\n",
    "    Acc = accData,\n",
    "    Pre = PresionData,\n",
    "    Rec = RecallData,\n",
    "    F1 = F1Data,\n",
    ")\n",
    "area1 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area1.title.align = \"center\"\n",
    "area2 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             stack=True, xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area2.title.align = \"center\"\n",
    "#########################################################################################################\n",
    "show(bar)\n",
    "show(p)\n",
    "#show(area1)\n",
    "#show(area2)\n",
    "show(row(area1, area2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "accData = [metrics.accuracy_score(y_deploy, y_pred_neigh),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm_linear), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_gtgini),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_IG), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGKN),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGDT), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_RF),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_AD), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_NB),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_LDA), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_QDA),           \n",
    "           metrics.accuracy_score(y_deploy, y_pred_LR),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_GP),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_gbm),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_xgboost),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_NN),        \n",
    "           metrics.accuracy_score(y_deploy, y_pred_SM),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_ASM)]\n",
    "          \n",
    "PresionData = [metrics.precision_score(y_deploy, y_pred_neigh),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm_linear),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm),\n",
    "               metrics.precision_score(y_deploy, y_pred_gtgini),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_IG),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGKN),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGDT),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_RF),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_AD),\n",
    "               metrics.precision_score(y_deploy, y_pred_NB),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_LDA),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_QDA),              \n",
    "               metrics.precision_score(y_deploy, y_pred_LR),\n",
    "               metrics.precision_score(y_deploy, y_pred_GP),\n",
    "               metrics.precision_score(y_deploy, y_pred_gbm),\n",
    "               metrics.precision_score(y_deploy, y_pred_xgboost),\n",
    "               metrics.precision_score(y_deploy, y_pred_NN),\n",
    "               metrics.precision_score(y_deploy, y_pred_SM),\n",
    "               metrics.precision_score(y_deploy, y_pred_ASM)]\n",
    "\n",
    "RecallData = [ metrics.recall_score(y_deploy, y_pred_neigh),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm_linear),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm),\n",
    "              metrics.recall_score(y_deploy, y_pred_gtgini),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_IG),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGKN),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGDT),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_RF),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_AD),\n",
    "              metrics.recall_score(y_deploy, y_pred_NB),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_LDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_QDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_LR),\n",
    "              metrics.recall_score(y_deploy, y_pred_GP),\n",
    "              metrics.recall_score(y_deploy, y_pred_gbm),\n",
    "              metrics.recall_score(y_deploy, y_pred_xgboost),       \n",
    "              metrics.recall_score(y_deploy, y_pred_NN),\n",
    "              metrics.recall_score(y_deploy, y_pred_SM),\n",
    "              metrics.recall_score(y_deploy, y_pred_ASM)]\n",
    "\n",
    "F1Data = [metrics.f1_score(y_deploy, y_pred_neigh),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm_linear),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm),\n",
    "          metrics.f1_score(y_deploy, y_pred_gtgini),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_IG),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGKN),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGDT),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_RF),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_AD),\n",
    "          metrics.f1_score(y_deploy, y_pred_NB),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_LDA),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_QDA),         \n",
    "          metrics.f1_score(y_deploy, y_pred_LR),\n",
    "          metrics.f1_score(y_deploy, y_pred_GP),\n",
    "          metrics.f1_score(y_deploy, y_pred_gbm),\n",
    "          metrics.f1_score(y_deploy, y_pred_xgboost),\n",
    "          metrics.f1_score(y_deploy, y_pred_NN),                             \n",
    "          metrics.f1_score(y_deploy, y_pred_SM),\n",
    "          metrics.f1_score(y_deploy, y_pred_ASM)]         \n",
    "\n",
    "\n",
    "\n",
    "N = len(accData)\n",
    "## necessary variables\n",
    "ind = np.arange(N)                # the x locations for the groups\n",
    "width = 0.17                     # the width of the bars\n",
    "## the bars\n",
    "rects1 = ax.bar(ind, accData, width,\n",
    "                color='black',\n",
    "                #yerr=menStd,\n",
    "                error_kw=dict(elinewidth=2,ecolor='red'))\n",
    "rects2 = ax.bar(ind+width, F1Data, width,\n",
    "                    color='red',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='black'))\n",
    "rects3 = ax.bar(ind+width+width, PresionData, width,\n",
    "                    color='green',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='blue'))\n",
    "rects4 = ax.bar(ind+width+width+width, RecallData, width,\n",
    "                    color='blue',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='green'))\n",
    "# axes and labels\n",
    "ax.set_xlim(-width,len(ind)+width)\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Name of Classifier')\n",
    "ax.set_title('Scores of different classifiers on Test Data')\n",
    "xTickMarks = ['Knn', 'LSVM', 'SVM', 'DT_gini', 'DT_entorpy' ,\n",
    "              'Bagging Knn' , 'Bagging DT' , 'Random Forest' , 'Ada Boost' ,\n",
    "              'NB' , 'LDA' , 'QDA' ,'Log. Reg.' ,'GP Class.','LightGBM','Xgboost',\n",
    "              'NN',  'Softmax', 'Decay SM']\n",
    "ax.set_xticks(ind+width)\n",
    "xtickNames = ax.set_xticklabels(xTickMarks)\n",
    "plt.setp(xtickNames, rotation=90, fontsize=10)\n",
    "## add a legend\n",
    "ax.legend( (rects1[0], rects2[0], rects3[0], rects4[0]), ('Acc.', 'F1' , 'Prec.' , 'Recall') , loc=8, fancybox=True, \n",
    "          frameon=True, shadow=True)\n",
    "ax.set_facecolor('0.9')\n",
    "\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "\n",
    "ax.spines['top'].set_linewidth(0.9)\n",
    "ax.spines['right'].set_linewidth(0.9)\n",
    "ax.spines['bottom'].set_linewidth(0.9)\n",
    "ax.spines['left'].set_linewidth(0.9)\n",
    "ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import pi\n",
    "from bokeh.charts import Bar, Area, defaults\n",
    "from bokeh.layouts import row\n",
    "from bokeh.charts.attributes import cat, color\n",
    "from bokeh.charts.operations import blend\n",
    "#from bokeh.charts.utils import df_from_json\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "############################################################################################################\n",
    "TOOLS = 'box_zoom,box_select,crosshair,resize,reset,lasso_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "#defaults.width = 1000\n",
    "#defaults.height = 800\n",
    "output_notebook()\n",
    "df1 = pd.DataFrame({'Matric': xTickMarks,\n",
    "                    'Accuracy':accData, \n",
    "                   'Precision': PresionData, \n",
    "                   'Recall': RecallData, \n",
    "                    'F1 Score': F1Data})\n",
    "############################################################################################################\n",
    "bar = Bar(df1,\n",
    "          values=blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "          label=cat(columns='Matric', sort=False),\n",
    "          stack=cat(columns='Score', sort=False),\n",
    "          color=color(columns='Score', palette=['SaddleBrown', 'Silver', 'Goldenrod', 'Grey'],\n",
    "                      sort=False),\n",
    "          legend='bottom_center', xlabel=\"List of Models\", ylabel=\"The Scores\",\n",
    "          title=\"Scores of different Models\", \n",
    "          tooltips=[('Score', '@Score'), ('Model', '@Matric')],\n",
    "          tools=TOOLS, plot_width=900, plot_height=800)\n",
    "bar.title.align = \"center\"\n",
    "bar.xaxis.major_label_orientation = pi/2\n",
    "###############################################################################################################\n",
    "p = Bar(df1, label='Matric', \n",
    "        values = blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "        group=cat(columns='Score', sort=False),\n",
    "        title=\"Scores of different Models\", legend='bottom_center',\n",
    "       tools=TOOLS, plot_width=900, plot_height=600,\n",
    "       xlabel='List of Models', ylabel='The Scores')\n",
    "p.title.align = \"center\"\n",
    "#p.yaxis.major_label_orientation = \"vertical\"\n",
    "p.xaxis.major_label_orientation = pi/2\n",
    "#########################################################################################################\n",
    "data = dict(\n",
    "    Acc = accData,\n",
    "    Pre = PresionData,\n",
    "    Rec = RecallData,\n",
    "    F1 = F1Data,\n",
    ")\n",
    "area1 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area1.title.align = \"center\"\n",
    "area2 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             stack=True, xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area2.title.align = \"center\"\n",
    "#########################################################################################################\n",
    "show(bar)\n",
    "show(p)\n",
    "#show(area1)\n",
    "#show(area2)\n",
    "show(row(area1, area2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Esiplon greedy and Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "accData = [metrics.accuracy_score(y_deploy, y_pred_neigh),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm_linear), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_gtgini),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_IG), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGKN),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGDT), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_RF),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_AD), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_NB),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_LDA), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_QDA),           \n",
    "           metrics.accuracy_score(y_deploy, y_pred_LR),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_GP),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_gbm),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_xgboost),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_NN),        \n",
    "           metrics.accuracy_score(y_deploy, y_pred_EG),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_AEG),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_SM),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_ASM)]\n",
    "          \n",
    "PresionData = [metrics.precision_score(y_deploy, y_pred_neigh),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm_linear),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm),\n",
    "               metrics.precision_score(y_deploy, y_pred_gtgini),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_IG),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGKN),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGDT),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_RF),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_AD),\n",
    "               metrics.precision_score(y_deploy, y_pred_NB),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_LDA),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_QDA),              \n",
    "               metrics.precision_score(y_deploy, y_pred_LR),\n",
    "               metrics.precision_score(y_deploy, y_pred_GP),\n",
    "               metrics.precision_score(y_deploy, y_pred_gbm),\n",
    "               metrics.precision_score(y_deploy, y_pred_xgboost),\n",
    "               metrics.precision_score(y_deploy, y_pred_NN),\n",
    "               metrics.precision_score(y_deploy, y_pred_EG),\n",
    "               metrics.precision_score(y_deploy, y_pred_AEG),\n",
    "               metrics.precision_score(y_deploy, y_pred_SM),\n",
    "               metrics.precision_score(y_deploy, y_pred_ASM)]\n",
    "\n",
    "RecallData = [ metrics.recall_score(y_deploy, y_pred_neigh),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm_linear),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm),\n",
    "              metrics.recall_score(y_deploy, y_pred_gtgini),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_IG),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGKN),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGDT),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_RF),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_AD),\n",
    "              metrics.recall_score(y_deploy, y_pred_NB),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_LDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_QDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_LR),\n",
    "              metrics.recall_score(y_deploy, y_pred_GP),\n",
    "              metrics.recall_score(y_deploy, y_pred_gbm),\n",
    "              metrics.recall_score(y_deploy, y_pred_xgboost),       \n",
    "              metrics.recall_score(y_deploy, y_pred_NN),\n",
    "              metrics.recall_score(y_deploy, y_pred_AEG),\n",
    "              metrics.recall_score(y_deploy, y_pred_EG),\n",
    "              metrics.recall_score(y_deploy, y_pred_SM),\n",
    "              metrics.recall_score(y_deploy, y_pred_ASM)]\n",
    "\n",
    "F1Data = [metrics.f1_score(y_deploy, y_pred_neigh),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm_linear),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm),\n",
    "          metrics.f1_score(y_deploy, y_pred_gtgini),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_IG),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGKN),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGDT),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_RF),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_AD),\n",
    "          metrics.f1_score(y_deploy, y_pred_NB),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_LDA),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_QDA),         \n",
    "          metrics.f1_score(y_deploy, y_pred_LR),\n",
    "          metrics.f1_score(y_deploy, y_pred_GP),\n",
    "          metrics.f1_score(y_deploy, y_pred_gbm),\n",
    "          metrics.f1_score(y_deploy, y_pred_xgboost),\n",
    "          metrics.f1_score(y_deploy, y_pred_NN),                             \n",
    "          metrics.f1_score(y_deploy, y_pred_EG),\n",
    "          metrics.f1_score(y_deploy, y_pred_AEG),\n",
    "          metrics.f1_score(y_deploy, y_pred_SM),\n",
    "          metrics.f1_score(y_deploy, y_pred_ASM)]         \n",
    "\n",
    "\n",
    "\n",
    "N = len(accData)\n",
    "## necessary variables\n",
    "ind = np.arange(N)                # the x locations for the groups\n",
    "width = 0.17                     # the width of the bars\n",
    "## the bars\n",
    "rects1 = ax.bar(ind, accData, width,\n",
    "                color='black',\n",
    "                #yerr=menStd,\n",
    "                error_kw=dict(elinewidth=2,ecolor='red'))\n",
    "rects2 = ax.bar(ind+width, F1Data, width,\n",
    "                    color='red',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='black'))\n",
    "rects3 = ax.bar(ind+width+width, PresionData, width,\n",
    "                    color='green',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='blue'))\n",
    "rects4 = ax.bar(ind+width+width+width, RecallData, width,\n",
    "                    color='blue',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='green'))\n",
    "# axes and labels\n",
    "ax.set_xlim(-width,len(ind)+width)\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Name of Classifier')\n",
    "ax.set_title('Scores of different classifiers on Test Data')\n",
    "xTickMarks = ['Knn', 'LSVM', 'SVM', 'DT_gini', 'DT_entorpy' ,\n",
    "              'Bagging Knn' , 'Bagging DT' , 'Random Forest' , 'Ada Boost' ,\n",
    "              'NB' , 'LDA' , 'QDA' ,'Log. Reg.' ,'GP Class.','LightGBM','Xgboost',\n",
    "              'NN',  'E Greedy' , 'Decay E Gr.' , 'Softmax', 'Decay SM']\n",
    "ax.set_xticks(ind+width)\n",
    "xtickNames = ax.set_xticklabels(xTickMarks)\n",
    "plt.setp(xtickNames, rotation=90, fontsize=10)\n",
    "## add a legend\n",
    "ax.legend( (rects1[0], rects2[0], rects3[0], rects4[0]), ('Acc.', 'F1' , 'Prec.' , 'Recall') , loc=8, fancybox=True, \n",
    "          frameon=True, shadow=True)\n",
    "ax.set_facecolor('0.9')\n",
    "\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "\n",
    "ax.spines['top'].set_linewidth(0.9)\n",
    "ax.spines['right'].set_linewidth(0.9)\n",
    "ax.spines['bottom'].set_linewidth(0.9)\n",
    "ax.spines['left'].set_linewidth(0.9)\n",
    "ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import pi\n",
    "from bokeh.charts import Bar, Area, defaults\n",
    "from bokeh.layouts import row\n",
    "from bokeh.charts.attributes import cat, color\n",
    "from bokeh.charts.operations import blend\n",
    "#from bokeh.charts.utils import df_from_json\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "############################################################################################################\n",
    "TOOLS = 'box_zoom,box_select,crosshair,resize,reset,lasso_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "#defaults.width = 1000\n",
    "#defaults.height = 800\n",
    "output_notebook()\n",
    "df1 = pd.DataFrame({'Matric': xTickMarks,\n",
    "                    'Accuracy':accData, \n",
    "                   'Precision': PresionData, \n",
    "                   'Recall': RecallData, \n",
    "                    'F1 Score': F1Data})\n",
    "############################################################################################################\n",
    "bar = Bar(df1,\n",
    "          values=blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "          label=cat(columns='Matric', sort=False),\n",
    "          stack=cat(columns='Score', sort=False),\n",
    "          color=color(columns='Score', palette=['SaddleBrown', 'Silver', 'Goldenrod', 'Grey'],\n",
    "                      sort=False),\n",
    "          legend='bottom_center', xlabel=\"List of Models\", ylabel=\"The Scores\",\n",
    "          title=\"Scores of different Models\", \n",
    "          tooltips=[('Score', '@Score'), ('Model', '@Matric')],\n",
    "          tools=TOOLS, plot_width=900, plot_height=800)\n",
    "bar.title.align = \"center\"\n",
    "bar.xaxis.major_label_orientation = pi/2\n",
    "###############################################################################################################\n",
    "p = Bar(df1, label='Matric', \n",
    "        values = blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "        group=cat(columns='Score', sort=False),\n",
    "        title=\"Scores of different Models\", legend='bottom_center',\n",
    "       tools=TOOLS, plot_width=900, plot_height=600,\n",
    "       xlabel='List of Models', ylabel='The Scores')\n",
    "p.title.align = \"center\"\n",
    "#p.yaxis.major_label_orientation = \"vertical\"\n",
    "p.xaxis.major_label_orientation = pi/2\n",
    "#########################################################################################################\n",
    "data = dict(\n",
    "    Acc = accData,\n",
    "    Pre = PresionData,\n",
    "    Rec = RecallData,\n",
    "    F1 = F1Data,\n",
    ")\n",
    "area1 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area1.title.align = \"center\"\n",
    "area2 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             stack=True, xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area2.title.align = \"center\"\n",
    "#########################################################################################################\n",
    "show(bar)\n",
    "show(p)\n",
    "#show(area1)\n",
    "#show(area2)\n",
    "show(row(area1, area2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hedge and EXP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "accData = [metrics.accuracy_score(y_deploy, y_pred_neigh),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm_linear), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_gtgini),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_IG), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGKN),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGDT), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_RF),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_AD), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_NB),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_LDA), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_QDA),           \n",
    "           metrics.accuracy_score(y_deploy, y_pred_LR),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_GP),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_gbm),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_xgboost),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_NN),        \n",
    "           metrics.accuracy_score(y_deploy, y_pred_HG),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_EXP)]\n",
    "          \n",
    "PresionData = [metrics.precision_score(y_deploy, y_pred_neigh),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm_linear),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm),\n",
    "               metrics.precision_score(y_deploy, y_pred_gtgini),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_IG),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGKN),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGDT),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_RF),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_AD),\n",
    "               metrics.precision_score(y_deploy, y_pred_NB),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_LDA),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_QDA),              \n",
    "               metrics.precision_score(y_deploy, y_pred_LR),\n",
    "               metrics.precision_score(y_deploy, y_pred_GP),\n",
    "               metrics.precision_score(y_deploy, y_pred_gbm),\n",
    "               metrics.precision_score(y_deploy, y_pred_xgboost),\n",
    "               metrics.precision_score(y_deploy, y_pred_NN),\n",
    "               metrics.precision_score(y_deploy, y_pred_HG),\n",
    "               metrics.precision_score(y_deploy, y_pred_EXP)]\n",
    "\n",
    "RecallData = [ metrics.recall_score(y_deploy, y_pred_neigh),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm_linear),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm),\n",
    "              metrics.recall_score(y_deploy, y_pred_gtgini),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_IG),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGKN),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGDT),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_RF),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_AD),\n",
    "              metrics.recall_score(y_deploy, y_pred_NB),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_LDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_QDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_LR),\n",
    "              metrics.recall_score(y_deploy, y_pred_GP),\n",
    "              metrics.recall_score(y_deploy, y_pred_gbm),\n",
    "              metrics.recall_score(y_deploy, y_pred_xgboost),       \n",
    "              metrics.recall_score(y_deploy, y_pred_NN),\n",
    "              metrics.recall_score(y_deploy, y_pred_HG),\n",
    "              metrics.recall_score(y_deploy, y_pred_EXP)]\n",
    "\n",
    "F1Data = [metrics.f1_score(y_deploy, y_pred_neigh),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm_linear),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm),\n",
    "          metrics.f1_score(y_deploy, y_pred_gtgini),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_IG),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGKN),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGDT),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_RF),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_AD),\n",
    "          metrics.f1_score(y_deploy, y_pred_NB),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_LDA),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_QDA),         \n",
    "          metrics.f1_score(y_deploy, y_pred_LR),\n",
    "          metrics.f1_score(y_deploy, y_pred_GP),\n",
    "          metrics.f1_score(y_deploy, y_pred_gbm),\n",
    "          metrics.f1_score(y_deploy, y_pred_xgboost),\n",
    "          metrics.f1_score(y_deploy, y_pred_NN),                             \n",
    "          metrics.f1_score(y_deploy, y_pred_HG),\n",
    "          metrics.f1_score(y_deploy, y_pred_EXP)]         \n",
    "\n",
    "\n",
    "\n",
    "N = len(accData)\n",
    "## necessary variables\n",
    "ind = np.arange(N)                # the x locations for the groups\n",
    "width = 0.17                     # the width of the bars\n",
    "## the bars\n",
    "rects1 = ax.bar(ind, accData, width,\n",
    "                color='black',\n",
    "                #yerr=menStd,\n",
    "                error_kw=dict(elinewidth=2,ecolor='red'))\n",
    "rects2 = ax.bar(ind+width, F1Data, width,\n",
    "                    color='red',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='black'))\n",
    "rects3 = ax.bar(ind+width+width, PresionData, width,\n",
    "                    color='green',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='blue'))\n",
    "rects4 = ax.bar(ind+width+width+width, RecallData, width,\n",
    "                    color='blue',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='green'))\n",
    "# axes and labels\n",
    "ax.set_xlim(-width,len(ind)+width)\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Name of Classifier')\n",
    "ax.set_title('Scores of different classifiers on Test Data')\n",
    "xTickMarks = ['Knn', 'LSVM', 'SVM', 'DT_gini', 'DT_entorpy' ,\n",
    "              'Bagging Knn' , 'Bagging DT' , 'Random Forest' , 'Ada Boost' ,\n",
    "              'NB' , 'LDA' , 'QDA' ,'Log. Reg.' ,'GP Class.','LightGBM','Xgboost',\n",
    "              'NN', 'Hedge', 'EXP3']\n",
    "ax.set_xticks(ind+width)\n",
    "xtickNames = ax.set_xticklabels(xTickMarks)\n",
    "plt.setp(xtickNames, rotation=90, fontsize=10)\n",
    "## add a legend\n",
    "ax.legend( (rects1[0], rects2[0], rects3[0], rects4[0]), ('Acc.', 'F1' , 'Prec.' , 'Recall') , loc=8, fancybox=True, \n",
    "          frameon=True, shadow=True)\n",
    "ax.set_facecolor('0.9')\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "\n",
    "ax.spines['top'].set_linewidth(0.9)\n",
    "ax.spines['right'].set_linewidth(0.9)\n",
    "ax.spines['bottom'].set_linewidth(0.9)\n",
    "ax.spines['left'].set_linewidth(0.9)\n",
    "ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import pi\n",
    "from bokeh.charts import Bar, Area, defaults\n",
    "from bokeh.layouts import row\n",
    "from bokeh.charts.attributes import cat, color\n",
    "from bokeh.charts.operations import blend\n",
    "#from bokeh.charts.utils import df_from_json\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "############################################################################################################\n",
    "TOOLS = 'box_zoom,box_select,crosshair,resize,reset,lasso_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "#defaults.width = 1000\n",
    "#defaults.height = 800\n",
    "output_notebook()\n",
    "df1 = pd.DataFrame({'Matric': xTickMarks,\n",
    "                    'Accuracy':accData, \n",
    "                   'Precision': PresionData, \n",
    "                   'Recall': RecallData, \n",
    "                    'F1 Score': F1Data})\n",
    "############################################################################################################\n",
    "bar = Bar(df1,\n",
    "          values=blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "          label=cat(columns='Matric', sort=False),\n",
    "          stack=cat(columns='Score', sort=False),\n",
    "          color=color(columns='Score', palette=['SaddleBrown', 'Silver', 'Goldenrod', 'Grey'],\n",
    "                      sort=False),\n",
    "          legend='bottom_center', xlabel=\"List of Models\", ylabel=\"The Scores\",\n",
    "          title=\"Scores of different Models\", \n",
    "          tooltips=[('Score', '@Score'), ('Model', '@Matric')],\n",
    "          tools=TOOLS, plot_width=900, plot_height=800)\n",
    "bar.title.align = \"center\"\n",
    "bar.xaxis.major_label_orientation = pi/2\n",
    "###############################################################################################################\n",
    "p = Bar(df1, label='Matric', \n",
    "        values = blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "        group=cat(columns='Score', sort=False),\n",
    "        title=\"Scores of different Models\", legend='bottom_center',\n",
    "       tools=TOOLS, plot_width=900, plot_height=600,\n",
    "       xlabel='List of Models', ylabel='The Scores')\n",
    "p.title.align = \"center\"\n",
    "#p.yaxis.major_label_orientation = \"vertical\"\n",
    "p.xaxis.major_label_orientation = pi/2\n",
    "#########################################################################################################\n",
    "data = dict(\n",
    "    Acc = accData,\n",
    "    Pre = PresionData,\n",
    "    Rec = RecallData,\n",
    "    F1 = F1Data,\n",
    ")\n",
    "area1 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area1.title.align = \"center\"\n",
    "area2 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             stack=True, xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area2.title.align = \"center\"\n",
    "#########################################################################################################\n",
    "show(bar)\n",
    "show(p)\n",
    "#show(area1)\n",
    "#show(area2)\n",
    "show(row(area1, area2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thompson Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "accData = [metrics.accuracy_score(y_deploy, y_pred_neigh),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm_linear), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_svm), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_gtgini),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_IG), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGKN),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_BGDT), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_RF),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_AD), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_NB),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_LDA), \n",
    "           metrics.accuracy_score(y_deploy, y_pred_dt_QDA),           \n",
    "           metrics.accuracy_score(y_deploy, y_pred_LR),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_GP),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_gbm),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_xgboost),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_NN),\n",
    "           metrics.accuracy_score(y_deploy, y_pred_TS)]\n",
    "          \n",
    "PresionData = [metrics.precision_score(y_deploy, y_pred_neigh),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm_linear),\n",
    "               metrics.precision_score(y_deploy, y_pred_svm),\n",
    "               metrics.precision_score(y_deploy, y_pred_gtgini),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_IG),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGKN),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_BGDT),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_RF),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_AD),\n",
    "               metrics.precision_score(y_deploy, y_pred_NB),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_LDA),\n",
    "               metrics.precision_score(y_deploy, y_pred_dt_QDA),              \n",
    "               metrics.precision_score(y_deploy, y_pred_LR),\n",
    "               metrics.precision_score(y_deploy, y_pred_GP),\n",
    "               metrics.precision_score(y_deploy, y_pred_gbm),\n",
    "               metrics.precision_score(y_deploy, y_pred_xgboost),\n",
    "               metrics.precision_score(y_deploy, y_pred_NN),\n",
    "               metrics.precision_score(y_deploy, y_pred_TS)]\n",
    "\n",
    "RecallData = [ metrics.recall_score(y_deploy, y_pred_neigh),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm_linear),\n",
    "              metrics.recall_score(y_deploy, y_pred_svm),\n",
    "              metrics.recall_score(y_deploy, y_pred_gtgini),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_IG),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGKN),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_BGDT),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_RF),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_AD),\n",
    "              metrics.recall_score(y_deploy, y_pred_NB),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_LDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_dt_QDA),\n",
    "              metrics.recall_score(y_deploy, y_pred_LR),\n",
    "              metrics.recall_score(y_deploy, y_pred_GP),\n",
    "              metrics.recall_score(y_deploy, y_pred_gbm),\n",
    "              metrics.recall_score(y_deploy, y_pred_xgboost),       \n",
    "              metrics.recall_score(y_deploy, y_pred_NN),\n",
    "              metrics.recall_score(y_deploy, y_pred_TS)]\n",
    "\n",
    "F1Data = [metrics.f1_score(y_deploy, y_pred_neigh),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm_linear),\n",
    "          metrics.f1_score(y_deploy, y_pred_svm),\n",
    "          metrics.f1_score(y_deploy, y_pred_gtgini),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_IG),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGKN),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_BGDT),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_RF),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_AD),\n",
    "          metrics.f1_score(y_deploy, y_pred_NB),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_LDA),\n",
    "          metrics.f1_score(y_deploy, y_pred_dt_QDA),         \n",
    "          metrics.f1_score(y_deploy, y_pred_LR),\n",
    "          metrics.f1_score(y_deploy, y_pred_GP),\n",
    "          metrics.f1_score(y_deploy, y_pred_gbm),\n",
    "          metrics.f1_score(y_deploy, y_pred_xgboost),\n",
    "          metrics.f1_score(y_deploy, y_pred_NN),                             \n",
    "          metrics.f1_score(y_deploy, y_pred_TS)]         \n",
    "\n",
    "\n",
    "\n",
    "N = len(accData)\n",
    "## necessary variables\n",
    "ind = np.arange(N)                # the x locations for the groups\n",
    "width = 0.17                     # the width of the bars\n",
    "## the bars\n",
    "rects1 = ax.bar(ind, accData, width,\n",
    "                color='black',\n",
    "                #yerr=menStd,\n",
    "                error_kw=dict(elinewidth=2,ecolor='red'))\n",
    "rects2 = ax.bar(ind+width, F1Data, width,\n",
    "                    color='red',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='black'))\n",
    "rects3 = ax.bar(ind+width+width, PresionData, width,\n",
    "                    color='green',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='blue'))\n",
    "rects4 = ax.bar(ind+width+width+width, RecallData, width,\n",
    "                    color='blue',\n",
    "                    #yerr=womenStd,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='green'))\n",
    "# axes and labels\n",
    "ax.set_xlim(-width,len(ind)+width)\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Name of Classifier')\n",
    "ax.set_title('Scores of different classifiers on Test Data')\n",
    "xTickMarks = ['Knn', 'LSVM', 'SVM', 'DT_gini', 'DT_entorpy' ,\n",
    "              'Bagging Knn' , 'Bagging DT' , 'Random Forest' , 'Ada Boost' ,\n",
    "              'NB' , 'LDA' , 'QDA' ,'Log. Reg.' ,'GP Class.','LightGBM','Xgboost',\n",
    "              'NN', 'Tomp. Sampling']\n",
    "ax.set_xticks(ind+width)\n",
    "xtickNames = ax.set_xticklabels(xTickMarks)\n",
    "plt.setp(xtickNames, rotation=90, fontsize=10, )\n",
    "## add a legend\n",
    "ax.legend( (rects1[0], rects2[0], rects3[0], rects4[0]), ('Acc.', 'F1' , 'Prec.' , 'Recall') , loc=8, fancybox=True, \n",
    "          frameon=True, shadow=True)\n",
    "ax.set_facecolor('0.9')\n",
    "\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "\n",
    "ax.spines['top'].set_linewidth(0.9)\n",
    "ax.spines['right'].set_linewidth(0.9)\n",
    "ax.spines['bottom'].set_linewidth(0.9)\n",
    "ax.spines['left'].set_linewidth(0.9)\n",
    "ax.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import pi\n",
    "from bokeh.charts import Bar, Area, defaults\n",
    "from bokeh.layouts import row\n",
    "from bokeh.charts.attributes import cat, color\n",
    "from bokeh.charts.operations import blend\n",
    "#from bokeh.charts.utils import df_from_json\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "############################################################################################################\n",
    "TOOLS = 'box_zoom,box_select,crosshair,resize,reset,lasso_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "#defaults.width = 1000\n",
    "#defaults.height = 800\n",
    "output_notebook()\n",
    "df1 = pd.DataFrame({'Matric': xTickMarks,\n",
    "                    'Accuracy':accData, \n",
    "                   'Precision': PresionData, \n",
    "                   'Recall': RecallData, \n",
    "                    'F1 Score': F1Data})\n",
    "############################################################################################################\n",
    "bar = Bar(df1,\n",
    "          values=blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "          label=cat(columns='Matric', sort=False),\n",
    "          stack=cat(columns='Score', sort=False),\n",
    "          color=color(columns='Score', palette=['SaddleBrown', 'Silver', 'Goldenrod', 'Grey'],\n",
    "                      sort=False),\n",
    "          legend='bottom_center', xlabel=\"List of Models\", ylabel=\"The Scores\",\n",
    "          title=\"Scores of different Models\", \n",
    "          tooltips=[('Score', '@Score'), ('Model', '@Matric')],\n",
    "          tools=TOOLS, plot_width=900, plot_height=800)\n",
    "bar.title.align = \"center\"\n",
    "bar.xaxis.major_label_orientation = pi/2\n",
    "###############################################################################################################\n",
    "p = Bar(df1, label='Matric', \n",
    "        values = blend('Accuracy', 'F1 Score', 'Precision','Recall', name='Scores', labels_name='Score'),\n",
    "        group=cat(columns='Score', sort=False),\n",
    "        title=\"Scores of different Models\", legend='bottom_center',\n",
    "       tools=TOOLS, plot_width=900, plot_height=600,\n",
    "       xlabel='List of Models', ylabel='The Scores')\n",
    "p.title.align = \"center\"\n",
    "#p.yaxis.major_label_orientation = \"vertical\"\n",
    "p.xaxis.major_label_orientation = pi/2\n",
    "#########################################################################################################\n",
    "data = dict(\n",
    "    Acc = accData,\n",
    "    Pre = PresionData,\n",
    "    Rec = RecallData,\n",
    "    F1 = F1Data,\n",
    ")\n",
    "area1 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area1.title.align = \"center\"\n",
    "area2 = Area(data, title=\"The trend of score over Models\", legend=\"bottom_center\",\n",
    "             stack=True, xlabel='List of Models', ylabel='The Scores',\n",
    "            tools=TOOLS, plot_width=450, plot_height=300)\n",
    "area2.title.align = \"center\"\n",
    "#########################################################################################################\n",
    "show(bar)\n",
    "show(p)\n",
    "#show(area1)\n",
    "#show(area2)\n",
    "show(row(area1, area2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(targetLabel))\n",
    "    plt.xticks(tick_marks, targetLabel)\n",
    "    plt.yticks(tick_marks, targetLabel)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "targetLabel = np.array(['pima','not pima'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_neigh)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute Confusion on LSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_svm_linear)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_svm)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on DT with gini \"CART\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_gtgini)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on DT with entory \"C5.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_dt_IG)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on Bagging with Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_dt_BGKN)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on Bagging with DT \"CART\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_dt_BGDT)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_dt_RF)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_dt_AD)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_NB)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_dt_LDA)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_dt_QDA)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_NN)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on UCB1 NN 2.5% neurals removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_NN1)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on NN 7.5% neurals removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_NN2)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on NN 65% neurals removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_NN3)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on NN 85% neurals removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_NN4)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on Epsilon Greedy neurals removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_EG)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on Decaying Epsilon Greedy neurals removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_AEG)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "plot_confusion_matrix(cm)\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on SOFTMAX neurals removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_SM)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "plot_confusion_matrix(cm)\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on DECAYING SOFTMAX neurals removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_ASM)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "plot_confusion_matrix(cm)\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on THOMPSON SAMPLING neurals removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_TS)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "plot_confusion_matrix(cm)\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on HEDGE neurals removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_HG)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "plot_confusion_matrix(cm)\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Confusion on EXP3 neurals removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_deploy, y_pred_EXP)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "plot_confusion_matrix(cm)\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "#plt.figure()\n",
    "plt.subplot(2,2,2)\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
