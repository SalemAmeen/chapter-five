{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import sys\n",
    "from time import time\n",
    "import logging\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn import metrics, grid_search\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from operator import itemgetter\n",
    "from sklearn.svm import SVC\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "from __future__ import print_function\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "print(__doc__)\n",
    "# fix random seed for reproducibility\n",
    "plt.rcParams['figure.figsize'] = (20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-30 00:05:16,380 Loading LFW people faces from /Users/salemameen/scikit_learn_data/lfw_home\n",
      "2017-01-30 00:05:16,538 Loading face #00001 / 01288\n",
      "2017-01-30 00:05:20,034 Loading face #01001 / 01288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size:\n",
      "n_samples: 1288\n",
      "n_features: 1850\n",
      "n_classes: 7\n"
     ]
    }
   ],
   "source": [
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Download the data, if not already on disk and load it as numpy arrays\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "# introspect the images arrays to find the shapes (for plotting)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "# for machine learning we use the 2 data directly (as relative pixel\n",
    "# positions info is ignored by this model)\n",
    "X = lfw_people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print(\"Total dataset size:\")\n",
    "print(\"n_samples: %d\" % n_samples)\n",
    "print(\"n_features: %d\" % n_features)\n",
    "print(\"n_classes: %d\" % n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make developement dataset for genrilization and final testing\n",
    "###############################################################################\n",
    "# Split into a training set and a test set using a stratified k fold\n",
    "\n",
    "# split into a training and testing set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# Extracting 20% testing data\n",
    "X_train_feature, X_deploy, y_train_feature, y_deploy = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42)\n",
    "# Make training and validation data sets for building the models and choose the hyperparameters\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_feature, y_train_feature, test_size=0.15, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 150 eigenfaces from 929 faces\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:52: DeprecationWarning: Class RandomizedPCA is deprecated; RandomizedPCA was deprecated in 0.18 and will be removed in 0.20. Use PCA(svd_solver='randomized') instead. The new implementation DOES NOT store whiten ``components_``. Apply transform to get them.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n",
    "# dataset): unsupervised feature extraction / dimensionality reduction\n",
    "n_components = 150\n",
    "\n",
    "print(\"Extracting the top %d eigenfaces from %d faces\"\n",
    "      % (n_components, X_train.shape[0]))\n",
    "pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "X_deploy = pca.transform(X_deploy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function of printing best three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaching for the best hyperparameters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.582 (std: 0.040)\n",
      "Parameters: {'algorithm': 'auto', 'n_neighbors': 3}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.582 (std: 0.026)\n",
      "Parameters: {'algorithm': 'auto', 'n_neighbors': 6}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.582 (std: 0.040)\n",
      "Parameters: {'algorithm': 'ball_tree', 'n_neighbors': 3}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "parameters =  {'n_neighbors': [1,2,3,4,5,6,7,8,9,10,11,12,13,14], 'algorithm': ['auto','ball_tree','kd_tree','brute']}\n",
    "knn = KNeighborsClassifier()\n",
    "clf = grid_search.GridSearchCV(knn, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "report(clf.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time for training KNN is  0.0027120113372802734 seconds \n"
     ]
    }
   ],
   "source": [
    "clf_neigh = KNeighborsClassifier(algorithm='auto' , n_neighbors=4)\n",
    "#Training\n",
    "start_time = time.time()\n",
    "clf_neigh.fit(X_train, y_train)\n",
    "print(\"The time for training KNN is  %s seconds \" % (time.time() - start_time))\n",
    "\n",
    "# Make a prediction\n",
    "y_pred = clf_neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel Sharon       0.62      0.45      0.53        11\n",
      "     Colin Powell       0.86      0.60      0.71        30\n",
      "  Donald Rumsfeld       0.36      0.40      0.38        10\n",
      "    George W Bush       0.70      0.96      0.81        72\n",
      "Gerhard Schroeder       1.00      0.21      0.35        14\n",
      "      Hugo Chavez       0.67      0.25      0.36         8\n",
      "       Tony Blair       0.60      0.60      0.60        20\n",
      "\n",
      "      avg / total       0.71      0.68      0.66       165\n",
      "\n",
      "[[ 5  0  1  4  0  0  1]\n",
      " [ 1 18  2  6  0  1  2]\n",
      " [ 1  1  4  4  0  0  0]\n",
      " [ 0  0  1 69  0  0  2]\n",
      " [ 0  0  1  7  3  0  3]\n",
      " [ 1  1  0  4  0  2  0]\n",
      " [ 0  1  2  5  0  0 12]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "total size of new array must be unchanged",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ff4b29393ff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m                      for i in range(y_pred.shape[0])]\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mplot_gallery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_titles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# plot the gallery of the most significative eigenfaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ff4b29393ff5>\u001b[0m in \u001b[0;36mplot_gallery\u001b[0;34m(images, titles, h, w, n_row, n_col)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_row\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: total size of new array must be unchanged"
     ]
    },
    {
     "data": {
      "application/pdf": "JVBERi0xLjQKJazcIKu6CjEgMCBvYmoKPDwgL1R5cGUgL0NhdGFsb2cgL1BhZ2VzIDIgMCBSID4+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\ncnR4cmVmCjU0ODEKJSVFT0YK\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJgAAACfCAYAAAAFxxCZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC/O30+qtWQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ebb9f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Quantitative evaluation of the model quality on the test set\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Qualitative evaluation of the predictions using matplotlib\n",
    "\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "\n",
    "# plot the result of the prediction on a portion of the test set\n",
    "\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
    "\n",
    "prediction_titles = [title(y_pred, y_test, target_names, i)\n",
    "                     for i in range(y_pred.shape[0])]\n",
    "\n",
    "plot_gallery(X_test, prediction_titles, h, w)\n",
    "\n",
    "# plot the gallery of the most significative eigenfaces\n",
    "\n",
    "eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM classifier\n",
    "### Seaching for the best hyperparameters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.780 (std: 0.021)\n",
      "Parameters: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.776 (std: 0.009)\n",
      "Parameters: {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.776 (std: 0.009)\n",
      "Parameters: {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "#parameters = {'kernel':('linear', 'rbf'), 'C':[1, 20]}\n",
    "parameters = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "svr = svm.SVC()\n",
    "clf = grid_search.GridSearchCV(svr, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "report(clf.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time for training SVM is  0.1848909854888916 seconds \n",
      "===================================================================\n",
      "The accuracy on validation dataset of Linear SVM: \t 0.848484848485\n",
      "Precision on validation dataset of Linear SVM:    \t 0.836025878883\n",
      "Recall on validation dataset of Linear SVM :      \t 0.78944547516\n",
      "F1 score on validation dataset of Linear SVM:     \t 0.804936300512\n",
      "===================================================================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.87      0.87      0.87        30\n",
      "          2       0.62      0.80      0.70        10\n",
      "          3       0.87      0.93      0.90        72\n",
      "          4       0.73      0.79      0.76        14\n",
      "          5       0.83      0.62      0.71         8\n",
      "          6       0.93      0.70      0.80        20\n",
      "\n",
      "avg / total       0.86      0.85      0.85       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_svm = SVC(C=10.0, gamma=0.001, kernel='rbf')\n",
    "#Training\n",
    "start_time = time.time()\n",
    "clf_svm.fit(X_train, y_train)\n",
    "print(\"The time for training SVM is  %s seconds \" % (time.time() - start_time))\n",
    "\n",
    "# Make a prediction\n",
    "y_pred = clf_svm.predict(X_test)\n",
    "\n",
    "print(\"===================================================================\")\n",
    "print(\"The accuracy on validation dataset of Linear SVM: \\t\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision on validation dataset of Linear SVM:    \\t\", metrics.precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Recall on validation dataset of Linear SVM :      \\t\", metrics.recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"F1 score on validation dataset of Linear SVM:     \\t\", metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"===================================================================\")\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=['0', '1', '2','3','4', '5', '6', '7']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decsion Tree classifier\n",
    "### Seaching for the best hyperparameters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.423 (std: 0.013)\n",
      "Parameters: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 4}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.421 (std: 0.012)\n",
      "Parameters: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 4}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.413 (std: 0.013)\n",
      "Parameters: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "parameters = {'criterion':('gini', 'entropy'),\n",
    "              'min_samples_split': [2, 3, 4],\n",
    "              'min_samples_leaf': [2, 3, 4]}\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "clf = grid_search.GridSearchCV(dt, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "report(clf.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time for training Decision Tree is  0.21408295631408691 seconds \n",
      "===================================================================\n",
      "The accuracy on validation dataset of Decision Tree: \t 0.454545454545\n",
      "Precision on validation dataset of Decision Tree:    \t 0.32662092759\n",
      "Recall on validation dataset of Decision Tree :      \t 0.324778396207\n",
      "F1 score on validation dataset of Decision Tree:     \t 0.319984379122\n",
      "===================================================================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.17      0.09      0.12        11\n",
      "          1       0.38      0.43      0.41        30\n",
      "          2       0.16      0.30      0.21        10\n",
      "          3       0.66      0.65      0.66        72\n",
      "          4       0.10      0.07      0.08        14\n",
      "          5       0.43      0.38      0.40         8\n",
      "          6       0.39      0.35      0.37        20\n",
      "\n",
      "avg / total       0.46      0.45      0.45       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dt_IG = DecisionTreeClassifier(criterion='entropy', min_samples_split=2, min_samples_leaf=4)\n",
    "#Training\n",
    "start_time = time.time()\n",
    "clf_dt_IG.fit(X_train, y_train)\n",
    "print(\"The time for training Decision Tree is  %s seconds \" % (time.time() - start_time))\n",
    "\n",
    "# Make a prediction\n",
    "y_pred = clf_dt_IG.predict(X_test)\n",
    "\n",
    "print(\"===================================================================\")\n",
    "print(\"The accuracy on validation dataset of Decision Tree: \\t\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision on validation dataset of Decision Tree:    \\t\", metrics.precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Recall on validation dataset of Decision Tree :      \\t\", metrics.recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"F1 score on validation dataset of Decision Tree:     \\t\", metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"===================================================================\")\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=['0', '1', '2','3','4', '5', '6', '7']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time for training Naive Bayes is  0.0033130645751953125 seconds \n",
      "===================================================================\n",
      "The accuracy on validation dataset of NB: \t 0.763636363636\n",
      "Precision on validation dataset of NB:    \t 0.757996531946\n",
      "Recall on validation dataset of NB :      \t 0.701911976912\n",
      "F1 score on validation dataset of NB:     \t 0.719802755815\n",
      "===================================================================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.73      0.70        11\n",
      "          1       0.79      0.73      0.76        30\n",
      "          2       0.89      0.80      0.84        10\n",
      "          3       0.76      0.90      0.83        72\n",
      "          4       0.70      0.50      0.58        14\n",
      "          5       0.67      0.75      0.71         8\n",
      "          6       0.83      0.50      0.62        20\n",
      "\n",
      "avg / total       0.77      0.76      0.76       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_NB = GaussianNB()\n",
    "#Training\n",
    "start_time = time.time()\n",
    "clf_NB.fit(X_train, y_train)\n",
    "print(\"The time for training Naive Bayes is  %s seconds \" % (time.time() - start_time))\n",
    "\n",
    "# Make a prediction\n",
    "y_pred = clf_NB.predict(X_test)\n",
    "\n",
    "print(\"===================================================================\")\n",
    "print(\"The accuracy on validation dataset of NB: \\t\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision on validation dataset of NB:    \\t\", metrics.precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Recall on validation dataset of NB :      \\t\", metrics.recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"F1 score on validation dataset of NB:     \\t\", metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"===================================================================\")\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=['0', '1', '2','3','4', '5', '6', '7']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis classifier\n",
    "### Seaching for the best hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.809 (std: 0.010)\n",
      "Parameters: {'solver': 'svd'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.808 (std: 0.011)\n",
      "Parameters: {'solver': 'lsqr'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/linalg/basic.py:884: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "parameters = {'solver':('svd', 'lsqr')}\n",
    "\n",
    "ld = LinearDiscriminantAnalysis()\n",
    "clf = grid_search.GridSearchCV(ld, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "report(clf.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time for training Decision Tree is  0.026546955108642578 seconds \n",
      "===================================================================\n",
      "The accuracy on validation dataset of LDA: \t 0.842424242424\n",
      "Precision on validation dataset of LDA:    \t 0.819866505161\n",
      "Recall on validation dataset of LDA :      \t 0.79369717584\n",
      "F1 score on validation dataset of LDA:     \t 0.799033357092\n",
      "===================================================================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90        11\n",
      "          1       0.75      0.80      0.77        30\n",
      "          2       0.78      0.70      0.74        10\n",
      "          3       0.91      0.93      0.92        72\n",
      "          4       0.71      0.86      0.77        14\n",
      "          5       0.60      0.75      0.67         8\n",
      "          6       1.00      0.70      0.82        20\n",
      "\n",
      "avg / total       0.86      0.84      0.84       165\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf_dt_LDA = LinearDiscriminantAnalysis()\n",
    "#Training\n",
    "start_time = time.time()\n",
    "clf_dt_LDA.fit(X_train, y_train)\n",
    "print(\"The time for training Decision Tree is  %s seconds \" % (time.time() - start_time))\n",
    "\n",
    "# Make a prediction\n",
    "y_pred = clf_dt_LDA.predict(X_test)\n",
    "\n",
    "print(\"===================================================================\")\n",
    "print(\"The accuracy on validation dataset of LDA: \\t\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision on validation dataset of LDA:    \\t\", metrics.precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Recall on validation dataset of LDA :      \\t\", metrics.recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"F1 score on validation dataset of LDA:     \\t\", metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"===================================================================\")\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=['0', '1', '2','3','4', '5', '6', '7']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Discriminant Analysis classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time for training Decision Tree is  0.03391098976135254 seconds \n",
      "===================================================================\n",
      "The accuracy on validation dataset of QDA: \t 0.436363636364\n",
      "Precision on validation dataset of QDA:    \t 0.0623376623377\n",
      "Recall on validation dataset of QDA :      \t 0.142857142857\n",
      "F1 score on validation dataset of QDA:     \t 0.0867992766727\n",
      "===================================================================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.00      0.00      0.00        30\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.44      1.00      0.61        72\n",
      "          4       0.00      0.00      0.00        14\n",
      "          5       0.00      0.00      0.00         8\n",
      "          6       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.19      0.44      0.27       165\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "clf_dt_QDA = QuadraticDiscriminantAnalysis()\n",
    "#Training\n",
    "start_time = time.time()\n",
    "clf_dt_QDA.fit(X_train, y_train)\n",
    "print(\"The time for training Decision Tree is  %s seconds \" % (time.time() - start_time))\n",
    "\n",
    "# Make a prediction\n",
    "y_pred = clf_dt_QDA.predict(X_test)\n",
    "\n",
    "print(\"===================================================================\")\n",
    "print(\"The accuracy on validation dataset of QDA: \\t\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision on validation dataset of QDA:    \\t\", metrics.precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Recall on validation dataset of QDA :      \\t\", metrics.recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"F1 score on validation dataset of QDA:     \\t\", metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"===================================================================\")\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=['0', '1', '2','3','4', '5', '6', '7']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks  classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: expected dense_input_1 to have shape (None, 4) but got array with shape (929, 150)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b9ba8c217c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Actual modelling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelsTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The time for training NN is  %s seconds \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelsTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1069\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[1;32m    979\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m                                    exception_prefix='model input')\n\u001b[0m\u001b[1;32m    982\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[1;32m    983\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: expected dense_input_1 to have shape (None, 4) but got array with shape (929, 150)"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "labelsTrain = np_utils.to_categorical(y_train)\n",
    "labelsTest = np_utils.to_categorical(y_test)                                              \n",
    "model = Sequential()\n",
    "model.add(Dense(20,\n",
    "                input_shape=(4,), \n",
    "                activation=\"relu\"))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(9, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer='adam')\n",
    "# Actual modelling\n",
    "start_time = time.time()\n",
    "model.fit(X_train, labelsTrain, verbose=0, batch_size=13, nb_epoch=100)\n",
    "print(\"The time for training NN is  %s seconds \" % (time.time() - start_time))\n",
    "score, accuracy = model.evaluate(X_test, labelsTest, batch_size=13, verbose=0)\n",
    "print(\"Test fraction correct (NN-Score) = {:.2f}\".format(score))\n",
    "print(\"Test fraction correct (NN-Accuracy) = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "print \"===================================================================\"\n",
    "print \"The accuracy on validation dataset of Neural Network: \\t\", metrics.accuracy_score(y_test, y_pred)\n",
    "print \"Precision on validation dataset of Neural Network:    \\t\", metrics.precision_score(y_test, y_pred, average=\"macro\")\n",
    "print \"Recall on validation dataset of Neural Network :      \\t\", metrics.recall_score(y_test, y_pred, average=\"macro\")\n",
    "print \"F1 score on validation dataset of Neural Network:     \\t\", metrics.f1_score(y_test, y_pred, average=\"macro\")\n",
    "print \"===================================================================\"\n",
    "print metrics.classification_report(y_test, y_pred, target_names=['0', '1', '2','3','4', '5', '6', '7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './chest/'\n",
    "sys.path.append(\"./chest\")\n",
    "model.save_weights('chestModelbest.hdf5',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('./chest/X_train', X_train)\n",
    "np.save('./chest/y_train', y_train)\n",
    "np.save('./chest/X_test', X_test)\n",
    "np.save('./chest/y_test', y_test)\n",
    "np.save('./chest/X_deploy', X_deploy)\n",
    "np.save('./chest/y_deploy', y_deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
